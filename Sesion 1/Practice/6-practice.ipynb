{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_qR5xTubPPN"
      },
      "source": [
        "# NLP Basics Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)]('https://colab.research.google.com/github/semurillas/NLP_MIAA_252/blob/main/Sesion%201/Practice/6-practice.ipynb')\n",
        "\n",
        "\n",
        "<center>\n",
        "\n",
        "<h1>üìö Maestr√≠a en Inteligencia Artificial Aplicada ‚Äì 3er Semestre</h1>\n",
        "\n",
        "<h3>Asignatura: Procesamiento de Lenguaje Natural</h3>\n",
        "\n",
        "<hr style=\"width:60%;\">\n",
        "\n",
        "<h2>üë®‚Äçüéì Estudiantes</h2>\n",
        "<ul style=\"list-style:none; padding:0; font-size:18px;\">\n",
        "    <li>Claudia Mart√≠nez</li>\n",
        "    <li>Sebasti√°n Murillas</li>\n",
        "    <li>Mario J. Castellanos</li>\n",
        "    <li>Enrique Manzano</li>\n",
        "    <li>Octavio Guerra</li>\n",
        "</ul>\n",
        "\n",
        "<hr style=\"width:60%;\">\n",
        "\n",
        "<h3>üìÖ Fecha: Agosto 10, 2025</h3>\n",
        "\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "ovt7LOQr8Slr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vAnJ-Z2bPPP"
      },
      "source": [
        "En este notebook vamos a poner en pr√°ctica algunos de los conceptos vistos en los notebooks anteriores (Secci√≥n Learning en Repositorio GitHub), aplicado a un corpus espec√≠fico que cada uno de los estudiantes del grupo ha seleccionado.\n",
        "\n",
        "## Referencias\n",
        "* [NLP - Natural Language Processing With Python](https://www.udemy.com/course/nlp-natural-language-processing-with-python)\n",
        "* [Natural Language Processing in Action](https://www.manning.com/books/natural-language-processing-in-action)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "wtYAN6nKbPPQ"
      },
      "outputs": [],
      "source": [
        "import importlib.metadata\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Use importlib.metadata to get installed packages\n",
        "installed_packages = [dist.metadata['Name'].lower() for dist in importlib.metadata.Distribution.discover()]\n",
        "IN_COLAB = 'google-colab' in installed_packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TapM8U6wbPPR",
        "outputId": "a3e5b948-ad06-4df1-9d4b-398c8001228e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 2)) (25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 3)) (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 4)) (0.45.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.8.7)\n",
            "Requirement already satisfied: es_dep_news_trf in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 10)) (3.8.0)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 13)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib==3.8.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (3.8.0)\n",
            "Requirement already satisfied: seaborn==0.12.2 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 15)) (0.12.2)\n",
            "Requirement already satisfied: scikit-learn==1.6 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 16)) (1.6.0)\n",
            "Requirement already satisfied: statsmodels==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 17)) (0.14.0)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 18)) (4.66.1)\n",
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (2.2.0)\n",
            "Requirement already satisfied: lightning==2.2.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (2.2.0.post0)\n",
            "Requirement already satisfied: tensorboard==2.16.2 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (2.16.2)\n",
            "Requirement already satisfied: bokeh==3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 22)) (3.5.0)\n",
            "Requirement already satisfied: transformers==4.41.2 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (4.41.2)\n",
            "Requirement already satisfied: datasets==2.19.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (2.19.1)\n",
            "Requirement already satisfied: torchinfo==1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 25)) (1.8.0)\n",
            "Requirement already satisfied: accelerate==0.30.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 26)) (0.30.1)\n",
            "Requirement already satisfied: evaluate==0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 27)) (0.4.2)\n",
            "Requirement already satisfied: sentence-transformers==3.0.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 28)) (3.0.1)\n",
            "Requirement already satisfied: gradio==4.36.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (4.36.1)\n",
            "Requirement already satisfied: ollama==0.2.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 30)) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 32)) (3.9.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 33)) (1.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 13)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 13)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 13)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 16)) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 16)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from statsmodels==0.14.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (2.2.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning==2.2.0.post0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.2.0.post0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (0.15.2)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.2.0.post0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (1.8.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning==2.2.0.post0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (2.5.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (3.1.3)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.5.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 22)) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.5.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 22)) (2025.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (0.34.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (0.6.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (0.7)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (3.12.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 26)) (5.9.5)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.0.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (1.0.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.27.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (6.5.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (3.11.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.12.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.12.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2.5.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.35.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 32)) (8.2.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.0.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (11.0.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.5.82)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2.0.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (1.1.7)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.4.2)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.17.2)\n",
            "Requirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from es_dep_news_trf->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 10)) (0.3.1)\n",
            "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es_dep_news_trf->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 10)) (0.1.1)\n",
            "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es_dep_news_trf->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 10)) (0.0.9)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 33)) (5.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (1.20.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.26.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.47.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!test '{IN_COLAB}' = 'True' && pip install -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('es_dep_news_trf')"
      ],
      "metadata": {
        "id": "vQpXXAHDlROI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv7k8AxJlb-c",
        "outputId": "4e69da42-cee1-4e3e-9fc8-bbc9aa444cd1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<spacy.lang.es.Spanish object at 0x78a2b50befd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Octavio Guerra\n",
        "\n",
        "El texto elegido corresponde a un documento **Word** presentado como entrega del *Proyecto II de Innovaci√≥n Tecnol√≥gica* del semestre anterior.\n",
        "\n",
        "Dado que el archivo est√° en formato **.docx**, primero debe convertirse a texto antes de su procesamiento.\n"
      ],
      "metadata": {
        "id": "fP-JOPvoplMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/Proyecto%20-%20Despliegue%20Modelos%20IA%20-%20Microservicios%20-%20Informe%20Final%20v3.docx\"\n",
        "docx_file_path = \"informe_final.docx\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(docx_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {docx_file_path}\")\n",
        "\n",
        "# Step 2: Read the DOCX file\n",
        "def read_docx(file_path):\n",
        "    \"\"\"Reads a .docx file and returns its text content.\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    all_text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        all_text.append(paragraph.text)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "text_content = read_docx(docx_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(docx_file_path,' has been processed with NLP model succesfully')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eCDCBQ9m9CK",
        "outputId": "9ddd5996-89a5-4b8a-e9d1-895e02e56982"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado como: informe_final.docx\n",
            "informe_final.docx  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U_5EHRobPPS",
        "outputId": "82405256-8960-4dfe-ed47-fbafe2216b33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. La soluci√≥n fue dise√±ada en respuesta a la propuesta y necesidades del cliente, considerando sus limitaciones actuales en infraestructura y software, y orientada a ofrecer escalabilidad, flexibilidad y facilidad de mantenimiento. Cada componente del sistema se implementa como un microservicio independiente, empaquetado"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "doc[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WwomnGPbPPT"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhRbyiPNbPPT"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC6KlqG-bPPT",
        "outputId": "2de6fb00-1844-4e48-e6ab-0f754897b541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4932"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEY_gn1sbPPT"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UObgeX6FbPPT",
        "outputId": "e8ba381a-231f-417f-e89c-f74db9a59e80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C6eFFBJbPPT"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh7xnToDbPPT",
        "outputId": "b3608e26-6dc5-4112-bdbb-5b59bcef6caa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios."
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "627K0GrVbPPU"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fscVIMCYbPPU",
        "outputId": "e0394a0e-0f34-4601-eeee-3d3202edd185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "Elaboraci√≥n         NOUN                nmod                elaboraci√≥n         \n",
            "de                  ADP                 case                de                  \n",
            "Plataforma          PROPN               nmod                Plataforma          \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "Microservicios      NOUN                obj                 microservicio       \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "Hector              PROPN               appos               Hector              \n",
            "Yesid               PROPN               flat                Yesid               \n",
            "Castelblanco        PROPN               flat                Castelblanco        \n",
            ",                   PUNCT               punct               ,                   \n",
            "Hector              PROPN               conj                Hector              \n",
            "Torres              PROPN               flat                Torres              \n",
            ",                   PUNCT               punct               ,                   \n",
            "Octavio             PROPN               conj                Octavio             \n",
            "Guerra              PROPN               flat                Guerra              \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "hector.castelblancocaro@u.icesi.edu.coPROPN               flat                hector.castelblancocaro@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "hector.torres@u.icesi.edu.coPROPN               flat                hector.torres@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "octavio.guerra@u.icesu.edu.coPROPN               appos               octavio.guerra@u.icesu.edu.co\n",
            "\n",
            "\n",
            "                  SPACE               dep                 \n",
            "\n",
            "                  \n",
            "Resumen             PROPN               ROOT                Resumen             \n",
            "‚Äì                   SYM                 nmod                ‚Äì                   \n",
            "                    SPACE               dep                                     \n",
            "Este                DET                 det                 este                \n",
            "trabajo             NOUN                nsubj               trabajo             \n",
            "presenta            VERB                punct               presentar           \n",
            "el                  DET                 det                 el                  \n",
            "desarrollo          NOUN                obj                 desarrollo          \n",
            "de                  ADP                 case                de                  \n",
            "una                 DET                 det                 uno                 \n",
            "plataforma          NOUN                nmod                plataforma          \n",
            "para                ADP                 case                para                \n",
            "el                  DET                 det                 el                  \n",
            "despliegue          NOUN                nmod                despliegue          \n",
            "de                  ADP                 case                de                  \n",
            "modelos             NOUN                nmod                modelo              \n",
            "de                  ADP                 case                de                  \n",
            "Inteligencia        PROPN               nmod                Inteligencia        \n",
            "Artificial          PROPN               flat                Artificial          \n",
            ",                   PUNCT               punct               ,                   \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "una                 DET                 det                 uno                 \n",
            "arquitectura        NOUN                obj                 arquitectura        \n",
            "de                  ADP                 case                de                  \n",
            "microservicios      NOUN                nmod                microservicio       \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sImQww8bPPU"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "bScSLf__bPPU"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'Inteligencia'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfUwlBP5bPPU",
        "outputId": "7bcd25d7-e8d0-4191-8e79-ef10ca37139b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 7 ocurrencias del  [{'TEXT': 'Inteligencia'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 43, 44),\n",
              " (12881893835109366681, 345, 346),\n",
              " (12881893835109366681, 436, 437),\n",
              " (12881893835109366681, 1966, 1967),\n",
              " (12881893835109366681, 2607, 2608),\n",
              " (12881893835109366681, 3730, 3731),\n",
              " (12881893835109366681, 4144, 4145)]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSl5Lon0bPPU"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MmR1eX4bPPU",
        "outputId": "68344aac-b977-44b0-f7df-d827544c2785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de una plataforma para el despliegue de modelos de **Inteligencia** Artificial , basada en una arquitectura de microservicios .\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "fundamentada en microservicios para el despliegue de modelos de **Inteligencia** Artificial ( IA ) , desarrollados y validados previamente\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de backends y en el campo de la **Inteligencia** Artificial . Para la construcci√≥n de APIs ligeras y\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de la plataforma de despliegue de modelos de **Inteligencia** Artificial ( IA ) , se ha adoptado una\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de la plataforma para el despliegue de modelos de **Inteligencia** Artificial ( IA ) se ha llevado a cabo\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de esta plataforma para el despliegue de modelos de **Inteligencia** Artificial se llev√≥ a cabo bas√°ndose en la arquitectura\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "un verdadero ecosistema de operaci√≥n continua para soluciones de **Inteligencia** Artificial . \n",
            " En conclusi√≥n , el enfoque actual\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8-oE7RDbPPU"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzAlyvDNbPPV",
        "outputId": "b39646e8-6e2a-4ee0-8b8c-c6450495e2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elaboraci√≥n de Plataforma basada en Microservicios\n",
            "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
            "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
            "\n",
            "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. \n",
            "\n",
            "---------------------------------------------\n",
            "Frente a este panorama, las arquitecturas basadas en microservicios han emergido como una alternativa s√≥lida a los enfoques monol√≠ticos tradicionales, permitiendo construir sistemas distribuidos, modulares y escalables con mayor flexibilidad y resiliencia.\n",
            "Este documento presenta el dise√±o e implementaci√≥n de una plataforma fundamentada en microservicios para el despliegue de modelos de Inteligencia Artificial (IA), desarrollados y validados previamente, con el objetivo de optimizar su ciclo de vida e integrarlos de manera eficiente en entornos productivos. \n",
            "\n",
            "---------------------------------------------\n",
            "La soluci√≥n propuesta se basa en el lenguaje de programaci√≥n Python, ampliamente reconocido por su versatilidad y adopci√≥n en el desarrollo de backends y en el campo de la Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Metodolog√≠a\n",
            "\n",
            "Para el desarrollo de la plataforma de despliegue de modelos de Inteligencia Artificial (IA), se ha adoptado una metodolog√≠a basada en buenas pr√°cticas ampliamente documentadas en la industria, combinando principios del enfoque de microservicios, la filosof√≠a 12-Factor App, y t√©cnicas modernas de Contenerizaci√≥n con Docker. \n",
            "\n",
            "---------------------------------------------\n",
            "Procedimientos y Herramientas Utilizadas\n",
            "\n",
            "El desarrollo de la plataforma para el despliegue de modelos de Inteligencia Artificial (IA) se ha llevado a cabo siguiendo un enfoque basado en microservicios, empleando contenedores Docker y orquestaci√≥n con herramientas modernas. \n",
            "\n",
            "---------------------------------------------\n",
            "El desarrollo de esta plataforma para el despliegue de modelos de Inteligencia Artificial se llev√≥ a cabo bas√°ndose en la arquitectura de microservicios, propuesta por el propio cliente. \n",
            "\n",
            "---------------------------------------------\n",
            "Esta evoluci√≥n consolidar√≠a la plataforma no solo como un sistema de despliegue de modelos, sino como un verdadero ecosistema de operaci√≥n continua para soluciones de Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Claudia Martinez\n"
      ],
      "metadata": {
        "id": "eJoQa_9Bpzgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/Proyecto%20-%20Despliegue%20Modelos%20IA%20-%20Microservicios%20-%20Informe%20Final%20v3.docx\"\n",
        "docx_file_path = \"informe_final.docx\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(docx_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {docx_file_path}\")\n",
        "\n",
        "# Step 2: Read the DOCX file\n",
        "def read_docx(file_path):\n",
        "    \"\"\"Reads a .docx file and returns its text content.\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    all_text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        all_text.append(paragraph.text)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "text_content = read_docx(docx_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(docx_file_path,' has been processed with NLP model succesfully')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ddd5996-89a5-4b8a-e9d1-895e02e56982",
        "id": "6pShrhvIhuwn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado como: informe_final.docx\n",
            "informe_final.docx  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82405256-8960-4dfe-ed47-fbafe2216b33",
        "id": "IKMB4pVQhuwo"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. La soluci√≥n fue dise√±ada en respuesta a la propuesta y necesidades del cliente, considerando sus limitaciones actuales en infraestructura y software, y orientada a ofrecer escalabilidad, flexibilidad y facilidad de mantenimiento. Cada componente del sistema se implementa como un microservicio independiente, empaquetado"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "doc[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RU6Tbw6huwp"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guc-E5othuwp"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de6fb00-1844-4e48-e6ab-0f754897b541",
        "id": "IrxNNk86huwp"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4932"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0koCQw0khuwq"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ba381a-231f-417f-e89c-f74db9a59e80",
        "id": "NvRYe4D6huwq"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1qj50m2huwq"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3608e26-6dc5-4112-bdbb-5b59bcef6caa",
        "id": "qM76Z3uzhuwr"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios."
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsvjz4Zshuwr"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0394a0e-0f34-4601-eeee-3d3202edd185",
        "id": "qB1_c8v9huwr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "Elaboraci√≥n         NOUN                nmod                elaboraci√≥n         \n",
            "de                  ADP                 case                de                  \n",
            "Plataforma          PROPN               nmod                Plataforma          \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "Microservicios      NOUN                obj                 microservicio       \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "Hector              PROPN               appos               Hector              \n",
            "Yesid               PROPN               flat                Yesid               \n",
            "Castelblanco        PROPN               flat                Castelblanco        \n",
            ",                   PUNCT               punct               ,                   \n",
            "Hector              PROPN               conj                Hector              \n",
            "Torres              PROPN               flat                Torres              \n",
            ",                   PUNCT               punct               ,                   \n",
            "Octavio             PROPN               conj                Octavio             \n",
            "Guerra              PROPN               flat                Guerra              \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "hector.castelblancocaro@u.icesi.edu.coPROPN               flat                hector.castelblancocaro@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "hector.torres@u.icesi.edu.coPROPN               flat                hector.torres@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "octavio.guerra@u.icesu.edu.coPROPN               appos               octavio.guerra@u.icesu.edu.co\n",
            "\n",
            "\n",
            "                  SPACE               dep                 \n",
            "\n",
            "                  \n",
            "Resumen             PROPN               ROOT                Resumen             \n",
            "‚Äì                   SYM                 nmod                ‚Äì                   \n",
            "                    SPACE               dep                                     \n",
            "Este                DET                 det                 este                \n",
            "trabajo             NOUN                nsubj               trabajo             \n",
            "presenta            VERB                punct               presentar           \n",
            "el                  DET                 det                 el                  \n",
            "desarrollo          NOUN                obj                 desarrollo          \n",
            "de                  ADP                 case                de                  \n",
            "una                 DET                 det                 uno                 \n",
            "plataforma          NOUN                nmod                plataforma          \n",
            "para                ADP                 case                para                \n",
            "el                  DET                 det                 el                  \n",
            "despliegue          NOUN                nmod                despliegue          \n",
            "de                  ADP                 case                de                  \n",
            "modelos             NOUN                nmod                modelo              \n",
            "de                  ADP                 case                de                  \n",
            "Inteligencia        PROPN               nmod                Inteligencia        \n",
            "Artificial          PROPN               flat                Artificial          \n",
            ",                   PUNCT               punct               ,                   \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "una                 DET                 det                 uno                 \n",
            "arquitectura        NOUN                obj                 arquitectura        \n",
            "de                  ADP                 case                de                  \n",
            "microservicios      NOUN                nmod                microservicio       \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RHsTFCOhuwr"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9rO8lLAhuws"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'Inteligencia'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcd25d7-e8d0-4191-8e79-ef10ca37139b",
        "id": "M6Eu-cIVhuws"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 7 ocurrencias del  [{'TEXT': 'Inteligencia'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 43, 44),\n",
              " (12881893835109366681, 345, 346),\n",
              " (12881893835109366681, 436, 437),\n",
              " (12881893835109366681, 1966, 1967),\n",
              " (12881893835109366681, 2607, 2608),\n",
              " (12881893835109366681, 3730, 3731),\n",
              " (12881893835109366681, 4144, 4145)]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOVTE0Pqhuws"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68344aac-b977-44b0-f7df-d827544c2785",
        "id": "iDwn1EoKhuws"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de una plataforma para el despliegue de modelos de **Inteligencia** Artificial , basada en una arquitectura de microservicios .\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "fundamentada en microservicios para el despliegue de modelos de **Inteligencia** Artificial ( IA ) , desarrollados y validados previamente\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de backends y en el campo de la **Inteligencia** Artificial . Para la construcci√≥n de APIs ligeras y\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de la plataforma de despliegue de modelos de **Inteligencia** Artificial ( IA ) , se ha adoptado una\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de la plataforma para el despliegue de modelos de **Inteligencia** Artificial ( IA ) se ha llevado a cabo\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de esta plataforma para el despliegue de modelos de **Inteligencia** Artificial se llev√≥ a cabo bas√°ndose en la arquitectura\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "un verdadero ecosistema de operaci√≥n continua para soluciones de **Inteligencia** Artificial . \n",
            " En conclusi√≥n , el enfoque actual\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tRBV3I-huwt"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39646e8-6e2a-4ee0-8b8c-c6450495e2a9",
        "id": "W0VWKw98huwt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elaboraci√≥n de Plataforma basada en Microservicios\n",
            "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
            "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
            "\n",
            "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. \n",
            "\n",
            "---------------------------------------------\n",
            "Frente a este panorama, las arquitecturas basadas en microservicios han emergido como una alternativa s√≥lida a los enfoques monol√≠ticos tradicionales, permitiendo construir sistemas distribuidos, modulares y escalables con mayor flexibilidad y resiliencia.\n",
            "Este documento presenta el dise√±o e implementaci√≥n de una plataforma fundamentada en microservicios para el despliegue de modelos de Inteligencia Artificial (IA), desarrollados y validados previamente, con el objetivo de optimizar su ciclo de vida e integrarlos de manera eficiente en entornos productivos. \n",
            "\n",
            "---------------------------------------------\n",
            "La soluci√≥n propuesta se basa en el lenguaje de programaci√≥n Python, ampliamente reconocido por su versatilidad y adopci√≥n en el desarrollo de backends y en el campo de la Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Metodolog√≠a\n",
            "\n",
            "Para el desarrollo de la plataforma de despliegue de modelos de Inteligencia Artificial (IA), se ha adoptado una metodolog√≠a basada en buenas pr√°cticas ampliamente documentadas en la industria, combinando principios del enfoque de microservicios, la filosof√≠a 12-Factor App, y t√©cnicas modernas de Contenerizaci√≥n con Docker. \n",
            "\n",
            "---------------------------------------------\n",
            "Procedimientos y Herramientas Utilizadas\n",
            "\n",
            "El desarrollo de la plataforma para el despliegue de modelos de Inteligencia Artificial (IA) se ha llevado a cabo siguiendo un enfoque basado en microservicios, empleando contenedores Docker y orquestaci√≥n con herramientas modernas. \n",
            "\n",
            "---------------------------------------------\n",
            "El desarrollo de esta plataforma para el despliegue de modelos de Inteligencia Artificial se llev√≥ a cabo bas√°ndose en la arquitectura de microservicios, propuesta por el propio cliente. \n",
            "\n",
            "---------------------------------------------\n",
            "Esta evoluci√≥n consolidar√≠a la plataforma no solo como un sistema de despliegue de modelos, sino como un verdadero ecosistema de operaci√≥n continua para soluciones de Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Sebastian Murillas"
      ],
      "metadata": {
        "id": "dEiqJ-w2hH_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/Proyecto%20-%20Despliegue%20Modelos%20IA%20-%20Microservicios%20-%20Informe%20Final%20v3.docx\"\n",
        "docx_file_path = \"informe_final.docx\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(docx_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {docx_file_path}\")\n",
        "\n",
        "# Step 2: Read the DOCX file\n",
        "def read_docx(file_path):\n",
        "    \"\"\"Reads a .docx file and returns its text content.\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    all_text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        all_text.append(paragraph.text)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "text_content = read_docx(docx_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(docx_file_path,' has been processed with NLP model succesfully')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ddd5996-89a5-4b8a-e9d1-895e02e56982",
        "id": "8Y0YKQoHh1Qn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado como: informe_final.docx\n",
            "informe_final.docx  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82405256-8960-4dfe-ed47-fbafe2216b33",
        "id": "Kmy4Qh8nh1Qo"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. La soluci√≥n fue dise√±ada en respuesta a la propuesta y necesidades del cliente, considerando sus limitaciones actuales en infraestructura y software, y orientada a ofrecer escalabilidad, flexibilidad y facilidad de mantenimiento. Cada componente del sistema se implementa como un microservicio independiente, empaquetado"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "doc[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD_UpRa7h1Qo"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKHZ3kuDh1Qp"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de6fb00-1844-4e48-e6ab-0f754897b541",
        "id": "ODhpmaGdh1Qp"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4932"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TAIK_7Jh1Qp"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ba381a-231f-417f-e89c-f74db9a59e80",
        "id": "VuMjRzINh1Qp"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVdwWPe8h1Qp"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3608e26-6dc5-4112-bdbb-5b59bcef6caa",
        "id": "NXQbC07Vh1Qq"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios."
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2ZDKv6wh1Qq"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0394a0e-0f34-4601-eeee-3d3202edd185",
        "id": "NVnQkkqph1Qq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "Elaboraci√≥n         NOUN                nmod                elaboraci√≥n         \n",
            "de                  ADP                 case                de                  \n",
            "Plataforma          PROPN               nmod                Plataforma          \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "Microservicios      NOUN                obj                 microservicio       \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "Hector              PROPN               appos               Hector              \n",
            "Yesid               PROPN               flat                Yesid               \n",
            "Castelblanco        PROPN               flat                Castelblanco        \n",
            ",                   PUNCT               punct               ,                   \n",
            "Hector              PROPN               conj                Hector              \n",
            "Torres              PROPN               flat                Torres              \n",
            ",                   PUNCT               punct               ,                   \n",
            "Octavio             PROPN               conj                Octavio             \n",
            "Guerra              PROPN               flat                Guerra              \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "hector.castelblancocaro@u.icesi.edu.coPROPN               flat                hector.castelblancocaro@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "hector.torres@u.icesi.edu.coPROPN               flat                hector.torres@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "octavio.guerra@u.icesu.edu.coPROPN               appos               octavio.guerra@u.icesu.edu.co\n",
            "\n",
            "\n",
            "                  SPACE               dep                 \n",
            "\n",
            "                  \n",
            "Resumen             PROPN               ROOT                Resumen             \n",
            "‚Äì                   SYM                 nmod                ‚Äì                   \n",
            "                    SPACE               dep                                     \n",
            "Este                DET                 det                 este                \n",
            "trabajo             NOUN                nsubj               trabajo             \n",
            "presenta            VERB                punct               presentar           \n",
            "el                  DET                 det                 el                  \n",
            "desarrollo          NOUN                obj                 desarrollo          \n",
            "de                  ADP                 case                de                  \n",
            "una                 DET                 det                 uno                 \n",
            "plataforma          NOUN                nmod                plataforma          \n",
            "para                ADP                 case                para                \n",
            "el                  DET                 det                 el                  \n",
            "despliegue          NOUN                nmod                despliegue          \n",
            "de                  ADP                 case                de                  \n",
            "modelos             NOUN                nmod                modelo              \n",
            "de                  ADP                 case                de                  \n",
            "Inteligencia        PROPN               nmod                Inteligencia        \n",
            "Artificial          PROPN               flat                Artificial          \n",
            ",                   PUNCT               punct               ,                   \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "una                 DET                 det                 uno                 \n",
            "arquitectura        NOUN                obj                 arquitectura        \n",
            "de                  ADP                 case                de                  \n",
            "microservicios      NOUN                nmod                microservicio       \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1aPjTJdh1Qq"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3Ejd4nWh1Qq"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'Inteligencia'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcd25d7-e8d0-4191-8e79-ef10ca37139b",
        "id": "tE2IcKklh1Qr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 7 ocurrencias del  [{'TEXT': 'Inteligencia'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 43, 44),\n",
              " (12881893835109366681, 345, 346),\n",
              " (12881893835109366681, 436, 437),\n",
              " (12881893835109366681, 1966, 1967),\n",
              " (12881893835109366681, 2607, 2608),\n",
              " (12881893835109366681, 3730, 3731),\n",
              " (12881893835109366681, 4144, 4145)]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abFWIVZFh1Qr"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68344aac-b977-44b0-f7df-d827544c2785",
        "id": "Kpcrdl_2h1Qr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de una plataforma para el despliegue de modelos de **Inteligencia** Artificial , basada en una arquitectura de microservicios .\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "fundamentada en microservicios para el despliegue de modelos de **Inteligencia** Artificial ( IA ) , desarrollados y validados previamente\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de backends y en el campo de la **Inteligencia** Artificial . Para la construcci√≥n de APIs ligeras y\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de la plataforma de despliegue de modelos de **Inteligencia** Artificial ( IA ) , se ha adoptado una\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de la plataforma para el despliegue de modelos de **Inteligencia** Artificial ( IA ) se ha llevado a cabo\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de esta plataforma para el despliegue de modelos de **Inteligencia** Artificial se llev√≥ a cabo bas√°ndose en la arquitectura\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "un verdadero ecosistema de operaci√≥n continua para soluciones de **Inteligencia** Artificial . \n",
            " En conclusi√≥n , el enfoque actual\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWFuu9Xbh1Qr"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39646e8-6e2a-4ee0-8b8c-c6450495e2a9",
        "id": "PxLLGBNYh1Qr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elaboraci√≥n de Plataforma basada en Microservicios\n",
            "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
            "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
            "\n",
            "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. \n",
            "\n",
            "---------------------------------------------\n",
            "Frente a este panorama, las arquitecturas basadas en microservicios han emergido como una alternativa s√≥lida a los enfoques monol√≠ticos tradicionales, permitiendo construir sistemas distribuidos, modulares y escalables con mayor flexibilidad y resiliencia.\n",
            "Este documento presenta el dise√±o e implementaci√≥n de una plataforma fundamentada en microservicios para el despliegue de modelos de Inteligencia Artificial (IA), desarrollados y validados previamente, con el objetivo de optimizar su ciclo de vida e integrarlos de manera eficiente en entornos productivos. \n",
            "\n",
            "---------------------------------------------\n",
            "La soluci√≥n propuesta se basa en el lenguaje de programaci√≥n Python, ampliamente reconocido por su versatilidad y adopci√≥n en el desarrollo de backends y en el campo de la Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Metodolog√≠a\n",
            "\n",
            "Para el desarrollo de la plataforma de despliegue de modelos de Inteligencia Artificial (IA), se ha adoptado una metodolog√≠a basada en buenas pr√°cticas ampliamente documentadas en la industria, combinando principios del enfoque de microservicios, la filosof√≠a 12-Factor App, y t√©cnicas modernas de Contenerizaci√≥n con Docker. \n",
            "\n",
            "---------------------------------------------\n",
            "Procedimientos y Herramientas Utilizadas\n",
            "\n",
            "El desarrollo de la plataforma para el despliegue de modelos de Inteligencia Artificial (IA) se ha llevado a cabo siguiendo un enfoque basado en microservicios, empleando contenedores Docker y orquestaci√≥n con herramientas modernas. \n",
            "\n",
            "---------------------------------------------\n",
            "El desarrollo de esta plataforma para el despliegue de modelos de Inteligencia Artificial se llev√≥ a cabo bas√°ndose en la arquitectura de microservicios, propuesta por el propio cliente. \n",
            "\n",
            "---------------------------------------------\n",
            "Esta evoluci√≥n consolidar√≠a la plataforma no solo como un sistema de despliegue de modelos, sino como un verdadero ecosistema de operaci√≥n continua para soluciones de Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Mario J. Castellanos"
      ],
      "metadata": {
        "id": "h6fmxnJvhOdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/Proyecto%20-%20Despliegue%20Modelos%20IA%20-%20Microservicios%20-%20Informe%20Final%20v3.docx\"\n",
        "docx_file_path = \"informe_final.docx\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(docx_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {docx_file_path}\")\n",
        "\n",
        "# Step 2: Read the DOCX file\n",
        "def read_docx(file_path):\n",
        "    \"\"\"Reads a .docx file and returns its text content.\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    all_text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        all_text.append(paragraph.text)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "text_content = read_docx(docx_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(docx_file_path,' has been processed with NLP model succesfully')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ddd5996-89a5-4b8a-e9d1-895e02e56982",
        "id": "VYB7kMoeh5pM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado como: informe_final.docx\n",
            "informe_final.docx  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82405256-8960-4dfe-ed47-fbafe2216b33",
        "id": "5i4DAInqh5pN"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. La soluci√≥n fue dise√±ada en respuesta a la propuesta y necesidades del cliente, considerando sus limitaciones actuales en infraestructura y software, y orientada a ofrecer escalabilidad, flexibilidad y facilidad de mantenimiento. Cada componente del sistema se implementa como un microservicio independiente, empaquetado"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "doc[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1bb_kmJh5pO"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnT4g35Mh5pO"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de6fb00-1844-4e48-e6ab-0f754897b541",
        "id": "hIMciFfTh5pO"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4932"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5Wr59dIh5pP"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ba381a-231f-417f-e89c-f74db9a59e80",
        "id": "X5bzkkI6h5pP"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-xlNDh-h5pP"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3608e26-6dc5-4112-bdbb-5b59bcef6caa",
        "id": "4eeAOkeih5pP"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios."
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4dCz2Yh5pQ"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0394a0e-0f34-4601-eeee-3d3202edd185",
        "id": "l3Sjx6Klh5pQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "Elaboraci√≥n         NOUN                nmod                elaboraci√≥n         \n",
            "de                  ADP                 case                de                  \n",
            "Plataforma          PROPN               nmod                Plataforma          \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "Microservicios      NOUN                obj                 microservicio       \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "Hector              PROPN               appos               Hector              \n",
            "Yesid               PROPN               flat                Yesid               \n",
            "Castelblanco        PROPN               flat                Castelblanco        \n",
            ",                   PUNCT               punct               ,                   \n",
            "Hector              PROPN               conj                Hector              \n",
            "Torres              PROPN               flat                Torres              \n",
            ",                   PUNCT               punct               ,                   \n",
            "Octavio             PROPN               conj                Octavio             \n",
            "Guerra              PROPN               flat                Guerra              \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "hector.castelblancocaro@u.icesi.edu.coPROPN               flat                hector.castelblancocaro@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "hector.torres@u.icesi.edu.coPROPN               flat                hector.torres@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "octavio.guerra@u.icesu.edu.coPROPN               appos               octavio.guerra@u.icesu.edu.co\n",
            "\n",
            "\n",
            "                  SPACE               dep                 \n",
            "\n",
            "                  \n",
            "Resumen             PROPN               ROOT                Resumen             \n",
            "‚Äì                   SYM                 nmod                ‚Äì                   \n",
            "                    SPACE               dep                                     \n",
            "Este                DET                 det                 este                \n",
            "trabajo             NOUN                nsubj               trabajo             \n",
            "presenta            VERB                punct               presentar           \n",
            "el                  DET                 det                 el                  \n",
            "desarrollo          NOUN                obj                 desarrollo          \n",
            "de                  ADP                 case                de                  \n",
            "una                 DET                 det                 uno                 \n",
            "plataforma          NOUN                nmod                plataforma          \n",
            "para                ADP                 case                para                \n",
            "el                  DET                 det                 el                  \n",
            "despliegue          NOUN                nmod                despliegue          \n",
            "de                  ADP                 case                de                  \n",
            "modelos             NOUN                nmod                modelo              \n",
            "de                  ADP                 case                de                  \n",
            "Inteligencia        PROPN               nmod                Inteligencia        \n",
            "Artificial          PROPN               flat                Artificial          \n",
            ",                   PUNCT               punct               ,                   \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "una                 DET                 det                 uno                 \n",
            "arquitectura        NOUN                obj                 arquitectura        \n",
            "de                  ADP                 case                de                  \n",
            "microservicios      NOUN                nmod                microservicio       \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7eaWYsYh5pQ"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_eXk8R4h5pR"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'Inteligencia'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcd25d7-e8d0-4191-8e79-ef10ca37139b",
        "id": "RLOsZIoLh5pR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 7 ocurrencias del  [{'TEXT': 'Inteligencia'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 43, 44),\n",
              " (12881893835109366681, 345, 346),\n",
              " (12881893835109366681, 436, 437),\n",
              " (12881893835109366681, 1966, 1967),\n",
              " (12881893835109366681, 2607, 2608),\n",
              " (12881893835109366681, 3730, 3731),\n",
              " (12881893835109366681, 4144, 4145)]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwQNrF2bh5pR"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68344aac-b977-44b0-f7df-d827544c2785",
        "id": "09_nrRsuh5pR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de una plataforma para el despliegue de modelos de **Inteligencia** Artificial , basada en una arquitectura de microservicios .\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "fundamentada en microservicios para el despliegue de modelos de **Inteligencia** Artificial ( IA ) , desarrollados y validados previamente\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de backends y en el campo de la **Inteligencia** Artificial . Para la construcci√≥n de APIs ligeras y\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de la plataforma de despliegue de modelos de **Inteligencia** Artificial ( IA ) , se ha adoptado una\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de la plataforma para el despliegue de modelos de **Inteligencia** Artificial ( IA ) se ha llevado a cabo\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de esta plataforma para el despliegue de modelos de **Inteligencia** Artificial se llev√≥ a cabo bas√°ndose en la arquitectura\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "un verdadero ecosistema de operaci√≥n continua para soluciones de **Inteligencia** Artificial . \n",
            " En conclusi√≥n , el enfoque actual\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sISLw8YEh5pS"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39646e8-6e2a-4ee0-8b8c-c6450495e2a9",
        "id": "OQiklWAFh5pS"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elaboraci√≥n de Plataforma basada en Microservicios\n",
            "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
            "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
            "\n",
            "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. \n",
            "\n",
            "---------------------------------------------\n",
            "Frente a este panorama, las arquitecturas basadas en microservicios han emergido como una alternativa s√≥lida a los enfoques monol√≠ticos tradicionales, permitiendo construir sistemas distribuidos, modulares y escalables con mayor flexibilidad y resiliencia.\n",
            "Este documento presenta el dise√±o e implementaci√≥n de una plataforma fundamentada en microservicios para el despliegue de modelos de Inteligencia Artificial (IA), desarrollados y validados previamente, con el objetivo de optimizar su ciclo de vida e integrarlos de manera eficiente en entornos productivos. \n",
            "\n",
            "---------------------------------------------\n",
            "La soluci√≥n propuesta se basa en el lenguaje de programaci√≥n Python, ampliamente reconocido por su versatilidad y adopci√≥n en el desarrollo de backends y en el campo de la Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Metodolog√≠a\n",
            "\n",
            "Para el desarrollo de la plataforma de despliegue de modelos de Inteligencia Artificial (IA), se ha adoptado una metodolog√≠a basada en buenas pr√°cticas ampliamente documentadas en la industria, combinando principios del enfoque de microservicios, la filosof√≠a 12-Factor App, y t√©cnicas modernas de Contenerizaci√≥n con Docker. \n",
            "\n",
            "---------------------------------------------\n",
            "Procedimientos y Herramientas Utilizadas\n",
            "\n",
            "El desarrollo de la plataforma para el despliegue de modelos de Inteligencia Artificial (IA) se ha llevado a cabo siguiendo un enfoque basado en microservicios, empleando contenedores Docker y orquestaci√≥n con herramientas modernas. \n",
            "\n",
            "---------------------------------------------\n",
            "El desarrollo de esta plataforma para el despliegue de modelos de Inteligencia Artificial se llev√≥ a cabo bas√°ndose en la arquitectura de microservicios, propuesta por el propio cliente. \n",
            "\n",
            "---------------------------------------------\n",
            "Esta evoluci√≥n consolidar√≠a la plataforma no solo como un sistema de despliegue de modelos, sino como un verdadero ecosistema de operaci√≥n continua para soluciones de Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Enrique Manzano"
      ],
      "metadata": {
        "id": "-QFIfdL-hS6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/Proyecto%20-%20Despliegue%20Modelos%20IA%20-%20Microservicios%20-%20Informe%20Final%20v3.docx\"\n",
        "docx_file_path = \"informe_final.docx\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(docx_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {docx_file_path}\")\n",
        "\n",
        "# Step 2: Read the DOCX file\n",
        "def read_docx(file_path):\n",
        "    \"\"\"Reads a .docx file and returns its text content.\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    all_text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        all_text.append(paragraph.text)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "text_content = read_docx(docx_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(docx_file_path,' has been processed with NLP model succesfully')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ddd5996-89a5-4b8a-e9d1-895e02e56982",
        "id": "9vD4Tp0ih8_z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado como: informe_final.docx\n",
            "informe_final.docx  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82405256-8960-4dfe-ed47-fbafe2216b33",
        "id": "xOiBMpzhh8_0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. La soluci√≥n fue dise√±ada en respuesta a la propuesta y necesidades del cliente, considerando sus limitaciones actuales en infraestructura y software, y orientada a ofrecer escalabilidad, flexibilidad y facilidad de mantenimiento. Cada componente del sistema se implementa como un microservicio independiente, empaquetado"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "doc[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mC1RThsh8_1"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThGH-9kzh8_1"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de6fb00-1844-4e48-e6ab-0f754897b541",
        "id": "xjkeR1xzh8_1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4932"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvnVMfB-h8_2"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ba381a-231f-417f-e89c-f74db9a59e80",
        "id": "3tSxi572h8_2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4irGr4th8_2"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3608e26-6dc5-4112-bdbb-5b59bcef6caa",
        "id": "21I1bT5bh8_2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios."
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkNHXf3Xh8_3"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0394a0e-0f34-4601-eeee-3d3202edd185",
        "id": "IvIL2goih8_3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "Elaboraci√≥n         NOUN                nmod                elaboraci√≥n         \n",
            "de                  ADP                 case                de                  \n",
            "Plataforma          PROPN               nmod                Plataforma          \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "Microservicios      NOUN                obj                 microservicio       \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "Hector              PROPN               appos               Hector              \n",
            "Yesid               PROPN               flat                Yesid               \n",
            "Castelblanco        PROPN               flat                Castelblanco        \n",
            ",                   PUNCT               punct               ,                   \n",
            "Hector              PROPN               conj                Hector              \n",
            "Torres              PROPN               flat                Torres              \n",
            ",                   PUNCT               punct               ,                   \n",
            "Octavio             PROPN               conj                Octavio             \n",
            "Guerra              PROPN               flat                Guerra              \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "hector.castelblancocaro@u.icesi.edu.coPROPN               flat                hector.castelblancocaro@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "hector.torres@u.icesi.edu.coPROPN               flat                hector.torres@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "octavio.guerra@u.icesu.edu.coPROPN               appos               octavio.guerra@u.icesu.edu.co\n",
            "\n",
            "\n",
            "                  SPACE               dep                 \n",
            "\n",
            "                  \n",
            "Resumen             PROPN               ROOT                Resumen             \n",
            "‚Äì                   SYM                 nmod                ‚Äì                   \n",
            "                    SPACE               dep                                     \n",
            "Este                DET                 det                 este                \n",
            "trabajo             NOUN                nsubj               trabajo             \n",
            "presenta            VERB                punct               presentar           \n",
            "el                  DET                 det                 el                  \n",
            "desarrollo          NOUN                obj                 desarrollo          \n",
            "de                  ADP                 case                de                  \n",
            "una                 DET                 det                 uno                 \n",
            "plataforma          NOUN                nmod                plataforma          \n",
            "para                ADP                 case                para                \n",
            "el                  DET                 det                 el                  \n",
            "despliegue          NOUN                nmod                despliegue          \n",
            "de                  ADP                 case                de                  \n",
            "modelos             NOUN                nmod                modelo              \n",
            "de                  ADP                 case                de                  \n",
            "Inteligencia        PROPN               nmod                Inteligencia        \n",
            "Artificial          PROPN               flat                Artificial          \n",
            ",                   PUNCT               punct               ,                   \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "una                 DET                 det                 uno                 \n",
            "arquitectura        NOUN                obj                 arquitectura        \n",
            "de                  ADP                 case                de                  \n",
            "microservicios      NOUN                nmod                microservicio       \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wZsr_vFh8_3"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXd85y4-h8_3"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'Inteligencia'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcd25d7-e8d0-4191-8e79-ef10ca37139b",
        "id": "DhXA9q1eh8_3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 7 ocurrencias del  [{'TEXT': 'Inteligencia'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 43, 44),\n",
              " (12881893835109366681, 345, 346),\n",
              " (12881893835109366681, 436, 437),\n",
              " (12881893835109366681, 1966, 1967),\n",
              " (12881893835109366681, 2607, 2608),\n",
              " (12881893835109366681, 3730, 3731),\n",
              " (12881893835109366681, 4144, 4145)]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VXsJUYsh8_4"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68344aac-b977-44b0-f7df-d827544c2785",
        "id": "ViH6_VnHh8_4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de una plataforma para el despliegue de modelos de **Inteligencia** Artificial , basada en una arquitectura de microservicios .\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "fundamentada en microservicios para el despliegue de modelos de **Inteligencia** Artificial ( IA ) , desarrollados y validados previamente\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de backends y en el campo de la **Inteligencia** Artificial . Para la construcci√≥n de APIs ligeras y\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de la plataforma de despliegue de modelos de **Inteligencia** Artificial ( IA ) , se ha adoptado una\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de la plataforma para el despliegue de modelos de **Inteligencia** Artificial ( IA ) se ha llevado a cabo\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de esta plataforma para el despliegue de modelos de **Inteligencia** Artificial se llev√≥ a cabo bas√°ndose en la arquitectura\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "un verdadero ecosistema de operaci√≥n continua para soluciones de **Inteligencia** Artificial . \n",
            " En conclusi√≥n , el enfoque actual\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27jRbexwh8_4"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39646e8-6e2a-4ee0-8b8c-c6450495e2a9",
        "id": "vVyg3g56h8_4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elaboraci√≥n de Plataforma basada en Microservicios\n",
            "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
            "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
            "\n",
            "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. \n",
            "\n",
            "---------------------------------------------\n",
            "Frente a este panorama, las arquitecturas basadas en microservicios han emergido como una alternativa s√≥lida a los enfoques monol√≠ticos tradicionales, permitiendo construir sistemas distribuidos, modulares y escalables con mayor flexibilidad y resiliencia.\n",
            "Este documento presenta el dise√±o e implementaci√≥n de una plataforma fundamentada en microservicios para el despliegue de modelos de Inteligencia Artificial (IA), desarrollados y validados previamente, con el objetivo de optimizar su ciclo de vida e integrarlos de manera eficiente en entornos productivos. \n",
            "\n",
            "---------------------------------------------\n",
            "La soluci√≥n propuesta se basa en el lenguaje de programaci√≥n Python, ampliamente reconocido por su versatilidad y adopci√≥n en el desarrollo de backends y en el campo de la Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Metodolog√≠a\n",
            "\n",
            "Para el desarrollo de la plataforma de despliegue de modelos de Inteligencia Artificial (IA), se ha adoptado una metodolog√≠a basada en buenas pr√°cticas ampliamente documentadas en la industria, combinando principios del enfoque de microservicios, la filosof√≠a 12-Factor App, y t√©cnicas modernas de Contenerizaci√≥n con Docker. \n",
            "\n",
            "---------------------------------------------\n",
            "Procedimientos y Herramientas Utilizadas\n",
            "\n",
            "El desarrollo de la plataforma para el despliegue de modelos de Inteligencia Artificial (IA) se ha llevado a cabo siguiendo un enfoque basado en microservicios, empleando contenedores Docker y orquestaci√≥n con herramientas modernas. \n",
            "\n",
            "---------------------------------------------\n",
            "El desarrollo de esta plataforma para el despliegue de modelos de Inteligencia Artificial se llev√≥ a cabo bas√°ndose en la arquitectura de microservicios, propuesta por el propio cliente. \n",
            "\n",
            "---------------------------------------------\n",
            "Esta evoluci√≥n consolidar√≠a la plataforma no solo como un sistema de despliegue de modelos, sino como un verdadero ecosistema de operaci√≥n continua para soluciones de Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "icesi-nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}