{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ohtar10/icesi-nlp/blob/main/Sesion1/6-practice.ipynb)\n",
    "\n",
    "En este notebook vamos a poner en práctica algunos de los conceptos vistos en los notebooks anteriores, aplicado a un corpus específico: \n",
    "[_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) por Ambrose Bierce (1890). Esta historia es de dominio público y el corpus fue obtenido de [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8).\n",
    "\n",
    "## Referencias\n",
    "* [NLP - Natural Language Processing With Python](https://www.udemy.com/course/nlp-natural-language-processing-with-python)\n",
    "* [Natural Language Processing in Action](https://www.manning.com/books/natural-language-processing-in-action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606223/2396000874.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "installed_packages = [package.key for package in pkg_resources.working_set]\n",
    "IN_COLAB = 'google-colab' in installed_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test '{IN_COLAB}' = 'True' && wget  https://github.com/Ohtar10/icesi-nlp/raw/refs/heads/main/requirements.txt && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Creamos el documento desde el archivo `owlcreek.txt`**<br>\n",
    "> Pista: Usa `with open('./owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test '{IN_COLAB}' = 'True' && wget  https://github.com/Ohtar10/icesi-nlp/raw/refs/heads/main/Sesion1/owlcreek.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./owlcreek.txt') as file:\n",
    "    doc = nlp(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El documento fue cargado exitosamente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cuantos tokens hay en el archivo?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Cuantas oraciones hay en el archivo?**\n",
    "<br>Pista: Necesitarás una lista primero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(doc.sents)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Imprime la segunda oración del documento**\n",
    "<br> Pista: Los índices comienzan en 0 y el título cuenta como la primera oración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The man's hands were behind\n",
       "his back, the wrists bound with a cord.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Por cada token en la oración anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                POS                 dep                 lemma               \n",
      "The                 DET                 det                 the                 \n",
      "man                 NOUN                poss                man                 \n",
      "'s                  PART                case                's                  \n",
      "hands               NOUN                nsubj               hand                \n",
      "were                AUX                 ROOT                be                  \n",
      "behind              ADP                 prep                behind              \n",
      "\n",
      "                   SPACE               dep                 \n",
      "                   \n",
      "his                 PRON                poss                his                 \n",
      "back                NOUN                pobj                back                \n",
      ",                   PUNCT               punct               ,                   \n",
      "the                 DET                 det                 the                 \n",
      "wrists              NOUN                appos               wrist               \n",
      "bound               VERB                acl                 bind                \n",
      "with                ADP                 prep                with                \n",
      "a                   DET                 det                 a                   \n",
      "cord                NOUN                pobj                cord                \n",
      ".                   PUNCT               punct               .                   \n",
      "                    SPACE               dep                                     \n"
     ]
    }
   ],
   "source": [
    "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
    "for token in sentences[1]:\n",
    "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *swimming vigorously* Write a matcher called 'Swimming' that finds**\n",
    "<br>\n",
    "Pista: Deberías incluir un patrón`'IS_SPACE': True` entre las dos palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{'LOWER': 'swimming'}, {'IS_SPACE': True}, {'LOWER': 'vigorously'}]\n",
    "matcher.add(\"Swimming\", [pattern])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12881893835109366681, 1274, 1277), (12881893835109366681, 3609, 3612)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches = matcher(doc)\n",
    "found_matches\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Imprime el texto al rededor de cada match encontrado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "By diving I could evade the bullets and, swimming\n",
       "vigorously, reach the bank, take to the woods and get away home"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = found_matches[0][1:]\n",
    "doc[start-9:end+13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "over his shoulder; he was now swimming\n",
       "vigorously with the current.  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = found_matches[1][1:]\n",
    "doc[start-7:end+5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Imprime la oración que contiene cada match encontrado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.   \n",
      "\n",
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    for _, start, end in found_matches:\n",
    "        if sentence.start <= start and sentence.end >= end:\n",
    "            print(sentence.text, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icesi-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
