{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/semurillas/NLP_MIAA_252/blob/Practice-1/Sesion%201/Practice/6-practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_qR5xTubPPN"
      },
      "source": [
        "# NLP Basics Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/semurillas/NLP_MIAA_252/blob/main/Sesion%201/Practice/6-practice.ipynb)\n",
        "\n",
        "\n",
        "<center>\n",
        "\n",
        "<h1>üìö Maestr√≠a en Inteligencia Artificial Aplicada ‚Äì 3er Semestre</h1>\n",
        "\n",
        "<h3>Asignatura: Procesamiento de Lenguaje Natural</h3>\n",
        "\n",
        "<hr style=\"width:60%;\">\n",
        "\n",
        "<h2>üë®‚Äçüéì Estudiantes</h2>\n",
        "<ul style=\"list-style:none; padding:0; font-size:18px;\">\n",
        "    <li>Claudia Mart√≠nez</li>\n",
        "    <li>Sebasti√°n Murillas</li>\n",
        "    <li>Mario J. Castellanos</li>\n",
        "    <li>Enrique Manzano</li>\n",
        "    <li>Octavio Guerra</li>\n",
        "</ul>\n",
        "\n",
        "<hr style=\"width:60%;\">\n",
        "\n",
        "<h3>üìÖ Fecha: Agosto 10, 2025</h3>\n",
        "\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "ovt7LOQr8Slr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vAnJ-Z2bPPP"
      },
      "source": [
        "En este notebook vamos a poner en pr√°ctica algunos de los conceptos vistos en los notebooks anteriores (Secci√≥n Learning en Repositorio GitHub), aplicado a un corpus espec√≠fico que cada uno de los estudiantes del grupo ha seleccionado.\n",
        "\n",
        "## Referencias\n",
        "* [NLP - Natural Language Processing With Python](https://www.udemy.com/course/nlp-natural-language-processing-with-python)\n",
        "* [Natural Language Processing in Action](https://www.manning.com/books/natural-language-processing-in-action)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzUKudj3v1Ag",
        "outputId": "0593488d-a593-4565-da5a-e08a3463e1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ‚Äîversi√≥n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eycfIK2pv8p3",
        "outputId": "65cdcf11-e174-42e7-db86-03b9dcf5268c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/‚Äîversi√≥n': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"es_dep_news_trf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKRYXCx4wN-o",
        "outputId": "eeb537ae-0843-4c09-caf8-b7d6351726a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_dep_news_trf')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtYAN6nKbPPQ"
      },
      "outputs": [],
      "source": [
        "import importlib.metadata\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Use importlib.metadata to get installed packages\n",
        "installed_packages = [dist.metadata['Name'].lower() for dist in importlib.metadata.Distribution.discover()]\n",
        "IN_COLAB = 'google-colab' in installed_packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import spacy.cli\n",
        "#spacy.cli.download(\"es_dep_news_trf\")"
      ],
      "metadata": {
        "id": "7o_zWVgHY269"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TapM8U6wbPPR",
        "outputId": "5b7ab28e-a34f-42be-c916-9b25794daf6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 2)) (24.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 4)) (0.45.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.8.7)\n",
            "Requirement already satisfied: es_dep_news_trf in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 10)) (3.8.0)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 13)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib==3.8.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (3.8.0)\n",
            "Requirement already satisfied: seaborn==0.12.2 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 15)) (0.12.2)\n",
            "Requirement already satisfied: scikit-learn==1.6 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 16)) (1.6.0)\n",
            "Requirement already satisfied: statsmodels==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 17)) (0.14.0)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 18)) (4.66.1)\n",
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (2.2.0)\n",
            "Requirement already satisfied: lightning==2.2.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (2.2.0.post0)\n",
            "Requirement already satisfied: tensorboard==2.16.2 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (2.16.2)\n",
            "Requirement already satisfied: bokeh==3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 22)) (3.5.0)\n",
            "Requirement already satisfied: transformers==4.41.2 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (4.41.2)\n",
            "Requirement already satisfied: datasets==2.19.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (2.19.1)\n",
            "Requirement already satisfied: torchinfo==1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 25)) (1.8.0)\n",
            "Requirement already satisfied: accelerate==0.30.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 26)) (0.30.1)\n",
            "Requirement already satisfied: evaluate==0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 27)) (0.4.2)\n",
            "Requirement already satisfied: sentence-transformers==3.0.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 28)) (3.0.1)\n",
            "Requirement already satisfied: gradio==4.36.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (4.36.1)\n",
            "Requirement already satisfied: ollama==0.2.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 30)) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 32)) (3.9.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 33)) (1.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 13)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 13)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 13)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 14)) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 16)) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 16)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from statsmodels==0.14.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (2.2.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning==2.2.0.post0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.2.0.post0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (0.15.2)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.2.0.post0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (1.8.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning==2.2.0.post0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 20)) (2.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.16.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 21)) (3.1.3)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.5.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 22)) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh==3.5.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 22)) (2025.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (0.34.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (0.6.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (0.7)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (3.12.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 26)) (5.9.5)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.0.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (1.0.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.27.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (6.5.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (3.11.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.12.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.12.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2.5.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.35.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 32)) (8.2.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.0.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (11.0.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (12.4.127)\n",
            "Requirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from es_dep_news_trf->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 10)) (0.3.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 33)) (5.4.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2.1.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 24)) (1.20.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2->transformers[torch]==4.41.2->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 23)) (1.1.7)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (3.4.3)\n",
            "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es_dep_news_trf->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 10)) (0.1.1)\n",
            "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es_dep_news_trf->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 10)) (0.0.9)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (7.3.0.post1)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.47.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 19)) (1.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.36.1->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 29)) (0.27.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt (line 7)) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!test '{IN_COLAB}' = 'True' && pip install -r https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('es_dep_news_trf')"
      ],
      "metadata": {
        "id": "vQpXXAHDlROI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv7k8AxJlb-c",
        "outputId": "505cf820-126c-4a46-9e84-15be83f5643d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<spacy.lang.es.Spanish object at 0x7b860bd07410>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Octavio Guerra\n",
        "\n",
        "El texto elegido corresponde a un documento **Word** presentado como entrega del *Proyecto II de Innovaci√≥n Tecnol√≥gica* del semestre anterior.\n",
        "\n",
        "Dado que el archivo est√° en formato **.docx**, primero debe convertirse a texto antes de su procesamiento.\n"
      ],
      "metadata": {
        "id": "fP-JOPvoplMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/Proyecto%20-%20Despliegue%20Modelos%20IA%20-%20Microservicios%20-%20Informe%20Final%20v3.docx\"\n",
        "docx_file_path = \"informe_final.docx\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(docx_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {docx_file_path}\")\n",
        "\n",
        "# Step 2: Read the DOCX file\n",
        "def read_docx(file_path):\n",
        "    \"\"\"Reads a .docx file and returns its text content.\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    all_text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        all_text.append(paragraph.text)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "text_content = read_docx(docx_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(docx_file_path,' has been processed with NLP model succesfully')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4eCDCBQ9m9CK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c5b4f8-94b5-4381-a991-91f6ceeb8958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado como: informe_final.docx\n",
            "informe_final.docx  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U_5EHRobPPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d35aff-0967-42df-a0ec-15329aa7e4ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. La soluci√≥n fue dise√±ada en respuesta a la propuesta y necesidades del cliente, considerando sus limitaciones actuales en infraestructura y software, y orientada a ofrecer escalabilidad, flexibilidad y facilidad de mantenimiento. Cada componente del sistema se implementa como un microservicio independiente, empaquetado"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "doc[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WwomnGPbPPT"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhRbyiPNbPPT"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC6KlqG-bPPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95829d1-2bcf-496e-ffc1-932aa00ef773"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4932"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEY_gn1sbPPT"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UObgeX6FbPPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f922c4ae-6166-4c07-d2c3-73cbe88a127f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C6eFFBJbPPT"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh7xnToDbPPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f372779-ee06-43ed-95b4-c5347df5a12f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios."
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "627K0GrVbPPU"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fscVIMCYbPPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d92078d-00c9-4dc0-f878-c6ecc2e03d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "Elaboraci√≥n         NOUN                nmod                elaboraci√≥n         \n",
            "de                  ADP                 case                de                  \n",
            "Plataforma          PROPN               nmod                Plataforma          \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "Microservicios      NOUN                obj                 microservicio       \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "Hector              PROPN               appos               Hector              \n",
            "Yesid               PROPN               flat                Yesid               \n",
            "Castelblanco        PROPN               flat                Castelblanco        \n",
            ",                   PUNCT               punct               ,                   \n",
            "Hector              PROPN               conj                Hector              \n",
            "Torres              PROPN               flat                Torres              \n",
            ",                   PUNCT               punct               ,                   \n",
            "Octavio             PROPN               conj                Octavio             \n",
            "Guerra              PROPN               flat                Guerra              \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "hector.castelblancocaro@u.icesi.edu.coPROPN               flat                hector.castelblancocaro@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "hector.torres@u.icesi.edu.coPROPN               flat                hector.torres@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "octavio.guerra@u.icesu.edu.coPROPN               appos               octavio.guerra@u.icesu.edu.co\n",
            "\n",
            "\n",
            "                  SPACE               dep                 \n",
            "\n",
            "                  \n",
            "Resumen             PROPN               ROOT                Resumen             \n",
            "‚Äì                   SYM                 nmod                ‚Äì                   \n",
            "                    SPACE               dep                                     \n",
            "Este                DET                 det                 este                \n",
            "trabajo             NOUN                nsubj               trabajo             \n",
            "presenta            VERB                punct               presentar           \n",
            "el                  DET                 det                 el                  \n",
            "desarrollo          NOUN                obj                 desarrollo          \n",
            "de                  ADP                 case                de                  \n",
            "una                 DET                 det                 uno                 \n",
            "plataforma          NOUN                nmod                plataforma          \n",
            "para                ADP                 case                para                \n",
            "el                  DET                 det                 el                  \n",
            "despliegue          NOUN                nmod                despliegue          \n",
            "de                  ADP                 case                de                  \n",
            "modelos             NOUN                nmod                modelo              \n",
            "de                  ADP                 case                de                  \n",
            "Inteligencia        PROPN               nmod                Inteligencia        \n",
            "Artificial          PROPN               flat                Artificial          \n",
            ",                   PUNCT               punct               ,                   \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "una                 DET                 det                 uno                 \n",
            "arquitectura        NOUN                obj                 arquitectura        \n",
            "de                  ADP                 case                de                  \n",
            "microservicios      NOUN                nmod                microservicio       \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sImQww8bPPU"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bScSLf__bPPU"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'Inteligencia'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfUwlBP5bPPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bff8da-37e3-4b43-ccd9-c39f57f5a17f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 7 ocurrencias del  [{'TEXT': 'Inteligencia'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 43, 44),\n",
              " (12881893835109366681, 345, 346),\n",
              " (12881893835109366681, 436, 437),\n",
              " (12881893835109366681, 1966, 1967),\n",
              " (12881893835109366681, 2607, 2608),\n",
              " (12881893835109366681, 3730, 3731),\n",
              " (12881893835109366681, 4144, 4145)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSl5Lon0bPPU"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MmR1eX4bPPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c7a859-ce43-431a-a021-7d4103b91da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de una plataforma para el despliegue de modelos de **Inteligencia** Artificial , basada en una arquitectura de microservicios .\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "fundamentada en microservicios para el despliegue de modelos de **Inteligencia** Artificial ( IA ) , desarrollados y validados previamente\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de backends y en el campo de la **Inteligencia** Artificial . Para la construcci√≥n de APIs ligeras y\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de la plataforma de despliegue de modelos de **Inteligencia** Artificial ( IA ) , se ha adoptado una\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de la plataforma para el despliegue de modelos de **Inteligencia** Artificial ( IA ) se ha llevado a cabo\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de esta plataforma para el despliegue de modelos de **Inteligencia** Artificial se llev√≥ a cabo bas√°ndose en la arquitectura\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "un verdadero ecosistema de operaci√≥n continua para soluciones de **Inteligencia** Artificial . \n",
            " En conclusi√≥n , el enfoque actual\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8-oE7RDbPPU"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzAlyvDNbPPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468a24dc-836d-4a4d-80d3-6daa00dfc033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elaboraci√≥n de Plataforma basada en Microservicios\n",
            "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
            "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
            "\n",
            "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. \n",
            "\n",
            "---------------------------------------------\n",
            "Frente a este panorama, las arquitecturas basadas en microservicios han emergido como una alternativa s√≥lida a los enfoques monol√≠ticos tradicionales, permitiendo construir sistemas distribuidos, modulares y escalables con mayor flexibilidad y resiliencia.\n",
            "Este documento presenta el dise√±o e implementaci√≥n de una plataforma fundamentada en microservicios para el despliegue de modelos de Inteligencia Artificial (IA), desarrollados y validados previamente, con el objetivo de optimizar su ciclo de vida e integrarlos de manera eficiente en entornos productivos. \n",
            "\n",
            "---------------------------------------------\n",
            "La soluci√≥n propuesta se basa en el lenguaje de programaci√≥n Python, ampliamente reconocido por su versatilidad y adopci√≥n en el desarrollo de backends y en el campo de la Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Metodolog√≠a\n",
            "\n",
            "Para el desarrollo de la plataforma de despliegue de modelos de Inteligencia Artificial (IA), se ha adoptado una metodolog√≠a basada en buenas pr√°cticas ampliamente documentadas en la industria, combinando principios del enfoque de microservicios, la filosof√≠a 12-Factor App, y t√©cnicas modernas de Contenerizaci√≥n con Docker. \n",
            "\n",
            "---------------------------------------------\n",
            "Procedimientos y Herramientas Utilizadas\n",
            "\n",
            "El desarrollo de la plataforma para el despliegue de modelos de Inteligencia Artificial (IA) se ha llevado a cabo siguiendo un enfoque basado en microservicios, empleando contenedores Docker y orquestaci√≥n con herramientas modernas. \n",
            "\n",
            "---------------------------------------------\n",
            "El desarrollo de esta plataforma para el despliegue de modelos de Inteligencia Artificial se llev√≥ a cabo bas√°ndose en la arquitectura de microservicios, propuesta por el propio cliente. \n",
            "\n",
            "---------------------------------------------\n",
            "Esta evoluci√≥n consolidar√≠a la plataforma no solo como un sistema de despliegue de modelos, sino como un verdadero ecosistema de operaci√≥n continua para soluciones de Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Claudia Martinez\n"
      ],
      "metadata": {
        "id": "eJoQa_9Bpzgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "import docx\n",
        "import requests\n",
        "import spacy\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "url =   \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/refs/heads/main/Texts/ESTADO%20DEL%20ARTE.docx\"\n",
        "docx_file_path = \"ESTADO DEL ARTE.docx\"\n",
        "\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(docx_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {docx_file_path}\")\n",
        "\n",
        "# Step 2: Read the DOCX file\n",
        "def read_docx(file_path):\n",
        "    \"\"\"Reads a .docx file and returns its text content.\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    all_text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        all_text.append(paragraph.text)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "text_content = read_docx(docx_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(docx_file_path,' has been processed with NLP model succesfully')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6pShrhvIhuwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80a8c03-b7fa-4043-c1a0-abc7114977ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n",
            "Archivo descargado como: ESTADO DEL ARTE.docx\n",
            "ESTADO DEL ARTE.docx  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IKMB4pVQhuwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80e887f-f7b3-4078-c7d2-9a635180f221"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ESTADO DEL ARTE\n",
              "El estado del arte de los agentes inform√°ticos para asignar competencias y recomendar cursos de capacitaci√≥n se encuentra en la intersecci√≥n de varias √°reas: inteligencia artificial, sistemas de recomendaci√≥n, gesti√≥n del talento humano, y tecnolog√≠as sem√°nticas. A continuaci√≥n presentamos un resumen estructurado del estado del arte, con foco en aplicaciones pr√°cticas para organizaciones:\n",
              "1. Definici√≥n y Rol de los Agentes Inform√°ticos en Capacitaci√≥n\n",
              "Los agentes inform√°ticos son programas aut√≥nomos dise√±ados para realizar tareas espec√≠ficas. En el √°mbito del talento humano, se usan para:"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "doc[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RU6Tbw6huwp"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guc-E5othuwp"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IrxNNk86huwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca5aea1-8c9c-41c5-cbc2-9e619707b592"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1305"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0koCQw0khuwq"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NvRYe4D6huwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adce558e-8dbd-4d1d-b5a9-66adab332a08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1qj50m2huwq"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qM76Z3uzhuwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d188fe8f-cd61-4509-bf92-97b15d55b0f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A continuaci√≥n presentamos un resumen estructurado del estado del arte, con foco en aplicaciones pr√°cticas para organizaciones:\n",
              "1."
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsvjz4Zshuwr"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qB1_c8v9huwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b06a32c-1950-4684-f3cd-2ad4e713a29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "A                   ADP                 advmod              a                   \n",
            "continuaci√≥n        NOUN                fixed               continuaci√≥n        \n",
            "presentamos         VERB                ROOT                presentar           \n",
            "un                  DET                 det                 uno                 \n",
            "resumen             NOUN                obj                 resumen             \n",
            "estructurado        ADJ                 amod                estructurado        \n",
            "del                 ADP                 case                del                 \n",
            "estado              NOUN                nmod                estado              \n",
            "del                 ADP                 case                del                 \n",
            "arte                NOUN                nmod                arte                \n",
            ",                   PUNCT               punct               ,                   \n",
            "con                 ADP                 case                con                 \n",
            "foco                NOUN                nmod                foco                \n",
            "en                  ADP                 case                en                  \n",
            "aplicaciones        NOUN                nmod                aplicaci√≥n          \n",
            "pr√°cticas           ADJ                 amod                pr√°ctico            \n",
            "para                ADP                 case                para                \n",
            "organizaciones      NOUN                nmod                organizaci√≥n        \n",
            ":                   PUNCT               punct               :                   \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "1                   NUM                 appos               1                   \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RHsTFCOhuwr"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "w9rO8lLAhuws"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'Agentes'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "M6Eu-cIVhuws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704fe58b-c546-47c3-ed1d-2c0685d782dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 3 ocurrencias del  [{'TEXT': 'Agentes'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 72, 73),\n",
              " (12881893835109366681, 823, 824),\n",
              " (12881893835109366681, 939, 940)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOVTE0Pqhuws"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iDwn1EoKhuws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880ac4ff-4c75-44ed-dec2-fa811a13f50e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ": \n",
            " 1 . Definici√≥n y Rol de los **Agentes** Inform√°ticos en Capacitaci√≥n \n",
            " Los agentes inform√°ticos son programas\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 4 . Avances Recientes en Investigaci√≥n Acad√©mica \n",
            " **Agentes** cognitivos basados en BDI ( Belief-Desire-Intention ) para tutor√≠a\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de capacitaci√≥n . \n",
            "\n",
            " 6 . Tendencias Futuras \n",
            " **Agentes** conversacionales que act√∫an como coaches virtuales . \n",
            " Personalizaci√≥n\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tRBV3I-huwt"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "W0VWKw98huwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40200f5-0bb3-4545-888f-bceea444e510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definici√≥n y Rol de los Agentes Inform√°ticos en Capacitaci√≥n\n",
            "Los agentes inform√°ticos son programas aut√≥nomos dise√±ados para realizar tareas espec√≠ficas. \n",
            "\n",
            "---------------------------------------------\n",
            "Avances Recientes en Investigaci√≥n Acad√©mica\n",
            "Agentes cognitivos basados en BDI (Belief-Desire-Intention) para tutor√≠a inteligente.\n",
            "Modelos de competencias din√°micas: las habilidades se adaptan al contexto organizacional y a cambios tecnol√≥gicos.\n",
            "Sistemas de recomendaci√≥n con embeddings sem√°nticos (BERT, SBERT) para vincular perfiles de usuarios con cat√°logos de cursos.\n",
            "Uso de MLOps para desplegar y mantener pipelines de recomendaci√≥n actualizados.\n",
            "5. \n",
            "\n",
            "---------------------------------------------\n",
            "Tendencias Futuras\n",
            "Agentes conversacionales que act√∫an como coaches virtuales.\n",
            "Personalizaci√≥n profunda con base en learning analytics.\n",
            "Uso de modelos de lenguaje grandes (LLMs) para analizar trayectorias laborales y generar planes de desarrollo.\n",
            "Integraci√≥n con redes corporativas de conocimiento para aprendizaje informal.\n",
            " \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Sebastian Murillas"
      ],
      "metadata": {
        "id": "dEiqJ-w2hH_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/Proyecto%20-%20Despliegue%20Modelos%20IA%20-%20Microservicios%20-%20Informe%20Final%20v3.docx\"\n",
        "docx_file_path = \"informe_final.docx\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(docx_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {docx_file_path}\")\n",
        "\n",
        "# Step 2: Read the DOCX file\n",
        "def read_docx(file_path):\n",
        "    \"\"\"Reads a .docx file and returns its text content.\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    all_text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        all_text.append(paragraph.text)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "text_content = read_docx(docx_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(docx_file_path,' has been processed with NLP model succesfully')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Y0YKQoHh1Qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e1c995-6143-410a-abc1-2736b660b572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado como: informe_final.docx\n",
            "informe_final.docx  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmy4Qh8nh1Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939c6b71-5ddb-42dc-e659-c9fa8bae61d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. La soluci√≥n fue dise√±ada en respuesta a la propuesta y necesidades del cliente, considerando sus limitaciones actuales en infraestructura y software, y orientada a ofrecer escalabilidad, flexibilidad y facilidad de mantenimiento. Cada componente del sistema se implementa como un microservicio independiente, empaquetado"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "doc[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD_UpRa7h1Qo"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKHZ3kuDh1Qp"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODhpmaGdh1Qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e975d8e-3cd5-479f-c93d-530ae566492a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4932"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TAIK_7Jh1Qp"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuMjRzINh1Qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47caeaf6-1914-455f-f5ef-17f073b4da59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVdwWPe8h1Qp"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXQbC07Vh1Qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbc07d4-8f01-4d65-8299-b2a5578b6286"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Elaboraci√≥n de Plataforma basada en Microservicios\n",
              "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
              "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
              "\n",
              "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios."
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2ZDKv6wh1Qq"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVnQkkqph1Qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccea8fea-b3ac-4697-aec6-5d412cf65c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "Elaboraci√≥n         NOUN                nmod                elaboraci√≥n         \n",
            "de                  ADP                 case                de                  \n",
            "Plataforma          PROPN               nmod                Plataforma          \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "Microservicios      NOUN                obj                 microservicio       \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "Hector              PROPN               appos               Hector              \n",
            "Yesid               PROPN               flat                Yesid               \n",
            "Castelblanco        PROPN               flat                Castelblanco        \n",
            ",                   PUNCT               punct               ,                   \n",
            "Hector              PROPN               conj                Hector              \n",
            "Torres              PROPN               flat                Torres              \n",
            ",                   PUNCT               punct               ,                   \n",
            "Octavio             PROPN               conj                Octavio             \n",
            "Guerra              PROPN               flat                Guerra              \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "hector.castelblancocaro@u.icesi.edu.coPROPN               flat                hector.castelblancocaro@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "hector.torres@u.icesi.edu.coPROPN               flat                hector.torres@u.icesi.edu.co\n",
            "                    SPACE               dep                                     \n",
            ",                   PUNCT               punct               ,                   \n",
            "octavio.guerra@u.icesu.edu.coPROPN               appos               octavio.guerra@u.icesu.edu.co\n",
            "\n",
            "\n",
            "                  SPACE               dep                 \n",
            "\n",
            "                  \n",
            "Resumen             PROPN               ROOT                Resumen             \n",
            "‚Äì                   SYM                 nmod                ‚Äì                   \n",
            "                    SPACE               dep                                     \n",
            "Este                DET                 det                 este                \n",
            "trabajo             NOUN                nsubj               trabajo             \n",
            "presenta            VERB                punct               presentar           \n",
            "el                  DET                 det                 el                  \n",
            "desarrollo          NOUN                obj                 desarrollo          \n",
            "de                  ADP                 case                de                  \n",
            "una                 DET                 det                 uno                 \n",
            "plataforma          NOUN                nmod                plataforma          \n",
            "para                ADP                 case                para                \n",
            "el                  DET                 det                 el                  \n",
            "despliegue          NOUN                nmod                despliegue          \n",
            "de                  ADP                 case                de                  \n",
            "modelos             NOUN                nmod                modelo              \n",
            "de                  ADP                 case                de                  \n",
            "Inteligencia        PROPN               nmod                Inteligencia        \n",
            "Artificial          PROPN               flat                Artificial          \n",
            ",                   PUNCT               punct               ,                   \n",
            "basada              ADJ                 amod                basado              \n",
            "en                  ADP                 case                en                  \n",
            "una                 DET                 det                 uno                 \n",
            "arquitectura        NOUN                obj                 arquitectura        \n",
            "de                  ADP                 case                de                  \n",
            "microservicios      NOUN                nmod                microservicio       \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1aPjTJdh1Qq"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3Ejd4nWh1Qq"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'Inteligencia'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE2IcKklh1Qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b978df-a28a-4cfd-fdf1-040524d0cfa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 7 ocurrencias del  [{'TEXT': 'Inteligencia'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 43, 44),\n",
              " (12881893835109366681, 345, 346),\n",
              " (12881893835109366681, 436, 437),\n",
              " (12881893835109366681, 1966, 1967),\n",
              " (12881893835109366681, 2607, 2608),\n",
              " (12881893835109366681, 3730, 3731),\n",
              " (12881893835109366681, 4144, 4145)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abFWIVZFh1Qr"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kpcrdl_2h1Qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8457f8df-fc11-4f94-9951-06777fdda2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de una plataforma para el despliegue de modelos de **Inteligencia** Artificial , basada en una arquitectura de microservicios .\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "fundamentada en microservicios para el despliegue de modelos de **Inteligencia** Artificial ( IA ) , desarrollados y validados previamente\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de backends y en el campo de la **Inteligencia** Artificial . Para la construcci√≥n de APIs ligeras y\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "desarrollo de la plataforma de despliegue de modelos de **Inteligencia** Artificial ( IA ) , se ha adoptado una\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de la plataforma para el despliegue de modelos de **Inteligencia** Artificial ( IA ) se ha llevado a cabo\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de esta plataforma para el despliegue de modelos de **Inteligencia** Artificial se llev√≥ a cabo bas√°ndose en la arquitectura\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "un verdadero ecosistema de operaci√≥n continua para soluciones de **Inteligencia** Artificial . \n",
            " En conclusi√≥n , el enfoque actual\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWFuu9Xbh1Qr"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxLLGBNYh1Qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfc657e-c546-4aab-b278-a21611927392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elaboraci√≥n de Plataforma basada en Microservicios\n",
            "Hector Yesid Castelblanco, Hector Torres , Octavio Guerra \n",
            "hector.castelblancocaro@u.icesi.edu.co  , hector.torres@u.icesi.edu.co  ,octavio.guerra@u.icesu.edu.co \n",
            "\n",
            "Resumen ‚Äì  Este trabajo presenta el desarrollo de una plataforma para el despliegue de modelos de Inteligencia Artificial, basada en una arquitectura de microservicios. \n",
            "\n",
            "---------------------------------------------\n",
            "Frente a este panorama, las arquitecturas basadas en microservicios han emergido como una alternativa s√≥lida a los enfoques monol√≠ticos tradicionales, permitiendo construir sistemas distribuidos, modulares y escalables con mayor flexibilidad y resiliencia.\n",
            "Este documento presenta el dise√±o e implementaci√≥n de una plataforma fundamentada en microservicios para el despliegue de modelos de Inteligencia Artificial (IA), desarrollados y validados previamente, con el objetivo de optimizar su ciclo de vida e integrarlos de manera eficiente en entornos productivos. \n",
            "\n",
            "---------------------------------------------\n",
            "La soluci√≥n propuesta se basa en el lenguaje de programaci√≥n Python, ampliamente reconocido por su versatilidad y adopci√≥n en el desarrollo de backends y en el campo de la Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Metodolog√≠a\n",
            "\n",
            "Para el desarrollo de la plataforma de despliegue de modelos de Inteligencia Artificial (IA), se ha adoptado una metodolog√≠a basada en buenas pr√°cticas ampliamente documentadas en la industria, combinando principios del enfoque de microservicios, la filosof√≠a 12-Factor App, y t√©cnicas modernas de Contenerizaci√≥n con Docker. \n",
            "\n",
            "---------------------------------------------\n",
            "Procedimientos y Herramientas Utilizadas\n",
            "\n",
            "El desarrollo de la plataforma para el despliegue de modelos de Inteligencia Artificial (IA) se ha llevado a cabo siguiendo un enfoque basado en microservicios, empleando contenedores Docker y orquestaci√≥n con herramientas modernas. \n",
            "\n",
            "---------------------------------------------\n",
            "El desarrollo de esta plataforma para el despliegue de modelos de Inteligencia Artificial se llev√≥ a cabo bas√°ndose en la arquitectura de microservicios, propuesta por el propio cliente. \n",
            "\n",
            "---------------------------------------------\n",
            "Esta evoluci√≥n consolidar√≠a la plataforma no solo como un sistema de despliegue de modelos, sino como un verdadero ecosistema de operaci√≥n continua para soluciones de Inteligencia Artificial. \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Mario J. Castellanos"
      ],
      "metadata": {
        "id": "h6fmxnJvhOdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "#url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/Proyecto%20-%20Despliegue%20Modelos%20IA%20-%20Microservicios%20-%20Informe%20Final%20v3.docx\"\n",
        "url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/Anteproyecto%20-%20Mario%20Nelson.docx\"\n",
        "docx_file_path = \"informe_final_mac.docx\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(docx_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {docx_file_path}\")\n",
        "\n",
        "# Step 2: Read the DOCX file\n",
        "def read_docx(file_path):\n",
        "    \"\"\"Reads a .docx file and returns its text content.\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    all_text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        all_text.append(paragraph.text)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "text_content = read_docx(docx_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(docx_file_path,' has been processed with NLP model succesfully')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a75cba-32d5-4b1a-f86c-41b7ae0fa6af",
        "id": "VYB7kMoeh5pM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado como: informe_final_mac.docx\n",
            "informe_final_mac.docx  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9193e0a-738b-4f3b-b54f-6a9842161bb2",
        "id": "5i4DAInqh5pN"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "FACULTAD DE INGENIER√çA\n",
              "-Maestr√≠a en Ciencia de Datos-\n",
              "\n",
              "\n",
              "\n",
              "1. Integrantes y Director del Trabajo.\n",
              "\n",
              "Integrante(s):\n",
              "Nelson Andr√©s Andrade Bonilla \n",
              "Mario Jos√© Castellanos Valencia\n",
              "\n",
              "Director:\n",
              "Hern√°n Dar√≠o Ben√≠tez Restrepo.\n",
              "Ingeniero Electr√≥nico\n",
              "PhD. en Ingenier√≠a El√©ctrica\n",
              "\n",
              "\n",
              "2. T√≠tulo del Proyecto o Trabajo de Grado.\n",
              "\n",
              "MODELO DE PRON√íSTICO PARA EL CONSUMO DE ENERG√çA EL√âCTRICA CON UN HORIZONTE DE TIEMPO A 1 Y 2 A√ëOS PARA EL MERCADO REGULADO DE ENERG√çA EN CALI.\n",
              "\n",
              "\n",
              "3. Contexto, Antecedentes y Justificaci√≥n.\n",
              "\n",
              "El Mercado El√©ctrico en Colombia, se organiza y desarrolla por mandato de la constituci√≥n de 1991 al decretar la obligatoriedad de la prestaci√≥n de los servicios p√∫blicos domiciliarios por parte del Estado (Aguilar D. & Diaz V., 2004). Posteriormente, en 1994, se promulgan las leyes 142 de Servicios P√∫blicos Domiciliarios ((Congreso de Colombia), 1994) y la 143 o ley El√©ctrica (Congreso & Colombia, 1994), que se fundamentan en la construcci√≥n de condiciones de competencia en las actividades de generaci√≥n, comercializaci√≥n y monopolio regulado que terminan en la transmisi√≥n, distribuci√≥n y entrega del servicio al usuario final. Al mismo tiempo, se crean las entidades regulatorias como la Comisi√≥n de Regulaci√≥n de Energ√≠a y Gas (CREG) y las entidades de control como la Superintendencia de Servicios P√∫blicos Domiciliarios (SSPD) reglamentada por la ley 142.\n",
              "¬†\n",
              "En Diciembre de 1992, la Comisi√≥n Nacional de Energ√≠a se transform√≥ en la Unidad de Planeaci√≥n Minero-Energ√©tica (UPME), la cual se encarga de desarrollar el plan energ√©tico nacional y las proyecciones de demanda de energ√≠a el√©ctrica, as√≠ como"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "doc[:300]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1bb_kmJh5pO"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnT4g35Mh5pO"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed650015-9e4e-43d0-f520-e26dcb4e5b92",
        "id": "hIMciFfTh5pO"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6997"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5Wr59dIh5pP"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd6d34f-14fc-4d70-a767-733cccd5082f",
        "id": "X5bzkkI6h5pP"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-xlNDh-h5pP"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80451ff3-1216-4250-9eee-6d34310847c3",
        "id": "4eeAOkeih5pP"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "5.2.2 Seleccionar el mejor modelo de aprendizaje autom√°tico para realizar la predicci√≥n de la demanda de energ√≠a el√©ctrica de largo plazo a partir de los modelos de Machine Learning dise√±ados."
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "sentences[50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4dCz2Yh5pQ"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e9f3ca-4855-4712-a463-cdca27f7f3b6",
        "id": "l3Sjx6Klh5pQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "FACULTAD            NOUN                ROOT                facultad            \n",
            "DE                  ADP                 case                DE                  \n",
            "INGENIER√çA          PROPN               nmod                INGENIER√çA          \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "-Maestr√≠a           PROPN               appos               -Maestr√≠a           \n",
            "en                  ADP                 case                en                  \n",
            "Ciencia             PROPN               nmod                Ciencia             \n",
            "de                  ADP                 case                de                  \n",
            "Datos-              PROPN               flat                Datos-              \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                SPACE               dep                 \n",
            "\n",
            "\n",
            "\n",
            "                \n",
            "1                   NUM                 appos               1                   \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7eaWYsYh5pQ"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_eXk8R4h5pR"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'demanda'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8714151-f1bd-41db-a093-5773e3113e6b",
        "id": "RLOsZIoLh5pR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 37 ocurrencias del  [{'TEXT': 'demanda'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 293, 294),\n",
              " (12881893835109366681, 357, 358),\n",
              " (12881893835109366681, 602, 603),\n",
              " (12881893835109366681, 751, 752),\n",
              " (12881893835109366681, 845, 846),\n",
              " (12881893835109366681, 864, 865),\n",
              " (12881893835109366681, 1063, 1064),\n",
              " (12881893835109366681, 1168, 1169),\n",
              " (12881893835109366681, 1184, 1185),\n",
              " (12881893835109366681, 1191, 1192),\n",
              " (12881893835109366681, 1359, 1360),\n",
              " (12881893835109366681, 1446, 1447),\n",
              " (12881893835109366681, 1469, 1470),\n",
              " (12881893835109366681, 1705, 1706),\n",
              " (12881893835109366681, 2078, 2079),\n",
              " (12881893835109366681, 2089, 2090),\n",
              " (12881893835109366681, 2118, 2119),\n",
              " (12881893835109366681, 2142, 2143),\n",
              " (12881893835109366681, 2271, 2272),\n",
              " (12881893835109366681, 2312, 2313),\n",
              " (12881893835109366681, 2353, 2354),\n",
              " (12881893835109366681, 2477, 2478),\n",
              " (12881893835109366681, 4412, 4413),\n",
              " (12881893835109366681, 4449, 4450),\n",
              " (12881893835109366681, 4467, 4468),\n",
              " (12881893835109366681, 4550, 4551),\n",
              " (12881893835109366681, 4691, 4692),\n",
              " (12881893835109366681, 4773, 4774),\n",
              " (12881893835109366681, 4835, 4836),\n",
              " (12881893835109366681, 4888, 4889),\n",
              " (12881893835109366681, 4970, 4971),\n",
              " (12881893835109366681, 5061, 5062),\n",
              " (12881893835109366681, 5108, 5109),\n",
              " (12881893835109366681, 5209, 5210),\n",
              " (12881893835109366681, 5307, 5308),\n",
              " (12881893835109366681, 5574, 5575),\n",
              " (12881893835109366681, 6855, 6856)]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwQNrF2bh5pR"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf06e65-d8ce-4ede-aeb9-1cf5a5a4f560",
        "id": "09_nrRsuh5pR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "desarrollar el plan energ√©tico nacional y las proyecciones de **demanda** de energ√≠a el√©ctrica , as√≠ como tambi√©n la creaci√≥n\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "con anticipaci√≥n y distribuida conforme a las proyecciones de **demanda** hacia las regiones . \n",
            "¬†\n",
            " Por otro lado ,\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            ". En este contexto los comercializadores deben pronosticar la **demanda** para no verse perjudicados dentro del mercado de energ√≠a\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "y factores como el flujo de caja , la **demanda** de los suscriptores y la fluctuaci√≥n de precios por\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "forma m√°s precisa las variables y proyecciones de la **demanda** , considerando incluso el ingreso de autogeneradores menores de\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "energ√≠a a trav√©s de paneles solares que modificar√°n la **demanda** en un futuro cercano si llegan a tener un\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "los comercializadores en Colombia es m√°s dif√≠cil predecir la **demanda** de largo plazo para saber cu√°nta energ√≠a comprar porque\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "incrementan las p√©rdidas no t√©cnicas o se desborda la **demanda** por auge en el sector de la construcci√≥n de\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "la construcci√≥n de vivienda lo cual tambi√©n afecta la **demanda** . \n",
            "\n",
            " Tabla 1 Proyecciones de demanda en el\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "afecta la demanda . \n",
            "\n",
            " Tabla 1 Proyecciones de **demanda** en el mercado regulado en kWh / mes realizadas\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "C√≥mo mejorar la predicci√≥n de largo plazo en la **demanda** de energ√≠a el√©ctrica en Cali , utilizando t√©cnicas y\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de aprendizaje autom√°tico para realizar la predicci√≥n de la **demanda** de energ√≠a el√©ctrica de largo plazo . \n",
            " 5.2.2\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de aprendizaje autom√°tico para realizar la predicci√≥n de la **demanda** de energ√≠a el√©ctrica de largo plazo a partir de\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "logrado identificar muchas de las variables que determinan la **demanda** de la energ√≠a el√©ctrica . En algunos estudios realizados\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            ". Alto ) . \t\n",
            "\n",
            " 6.1.2 Pron√≥sticos de la **demanda** de energ√≠a el√©ctrica . \n",
            "\n",
            " El proceso de pronosticar\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "energ√≠a el√©ctrica . \n",
            "\n",
            " El proceso de pronosticar la **demanda** de electricidad por parte de los actores del mercado\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de pron√≥stico y en los determinantes del consumo o **demanda** de electricidad . Rueda et al . ( Rueda\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            ") describen porqu√© es importante el pron√≥stico de la **demanda** de electricidad por horizontes seg√∫n el tipo de actor\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "el objetivo de este proyecto , el pron√≥stico de **demanda** es un insumo fundamental para el an√°lisis del comportamiento\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "han desarrollado numerosos m√©todos para la previsi√≥n de la **demanda** de electricidad , en su mayor√≠a de corto plazo\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " La soluci√≥n al problema del pron√≥stico de la **demanda** de electricidad de largo plazo se encuentra en el\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "selecci√≥n de ellos ser√° la base para pronosticar la **demanda** de electricidad en Colombia en este proyecto . \n",
            "\n",
            "\n",
            "\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "planteamiento del modelo ¬† que ¬† permita predecir la **demanda** de energ√≠a el√©ctrica en un horizonte de mediano-largo plazo\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "econom√©tricos , predicci√≥n en series temporales , pron√≥stico de **demanda** de electricidad . \n",
            "\n",
            "\n",
            " 7.1 Trabajos seleccionados \n",
            "\n",
            " Se\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "Se encontr√≥ mucha literatura relacionada con el pron√≥stico de **demanda** de electricidad   de corto plazo , a diferencia\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "de llenar un vac√≠o en el pron√≥stico de la **demanda** de energ√≠a el√©ctrica de largo plazo . Se utilizaron\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "el impacto de cambios socioecon√≥micos y clim√°ticos en la **demanda** de energ√≠a el√©ctrica mensual a largo plazo . Se\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "ser el mas adecuado para el pron√≥stico de la **demanda** de energ√≠a el√©ctrica de largo plazo en Hong Kong\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "que tienen mayor impacto en la predicci√≥n de la **demanda** de energ√≠a . Se utilizaron modelos de regresi√≥n m√∫ltiple\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "que mas impacto tienen en la predicci√≥n de la **demanda** de energ√≠a para el primer proceso son los usuarios\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "con el fin de involucrar los determinantes de la **demanda** y la oferta para investigar las relaciones causales a\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "con datos de 1990 a 2018 y proyecciones de **demanda** hasta 2050 . \n",
            "\n",
            " 7.1.3 T√©cnicas de predicci√≥n en\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "Este estudio fue realizado para la predicci√≥n de la **demanda** de energ√≠a para el Sistema   Operador Independiente de\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "mejores resultados al XGBoost y LR en predicciones de **demanda** de electricidad de corto y largo plazo . \n",
            "\n",
            "\n",
            "\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            ". \n",
            " Contexto : relacionados con el consumo o **demanda** de electricidad y su pron√≥stico a largo plazo .\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "proyecto de anal√≠tica de impactar con respecto a la **demanda** de energ√≠a el√©ctrica . \n",
            "\n",
            " Evaluar la situaci√≥n :\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            ") . Avances recientes en la predicci√≥n de la **demanda** de electricidad usando modelos no lineales . DYNA (\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sISLw8YEh5pS"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4078a6d2-dde4-44fe-cd52-12cffa40702d",
        "id": "OQiklWAFh5pS"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En Diciembre de 1992, la Comisi√≥n Nacional de Energ√≠a se transform√≥ en la Unidad de Planeaci√≥n Minero-Energ√©tica (UPME), la cual se encarga de desarrollar el plan energ√©tico nacional y las proyecciones de demanda de energ√≠a el√©ctrica, as√≠ como tambi√©n la creaci√≥n del plan de expansi√≥n y transmisi√≥n de energ√≠a para todo el territorio nacional. \n",
            "\n",
            "---------------------------------------------\n",
            "Estos planes son necesarios y se llevan a cabo para asegurar la disponibilidad energ√©tica permitiendo controlar tanto el flujo como la cantidad de energ√≠a el√©ctrica que debe ser generada o adquirida con anticipaci√≥n y distribuida conforme a las proyecciones de demanda hacia las regiones. \n",
            "\n",
            "---------------------------------------------\n",
            "En este contexto los comercializadores deben pronosticar la demanda para no verse perjudicados dentro del mercado de energ√≠a y poder cumplir con el mandato de la constituci√≥n y la ley en la prestaci√≥n de este servicio. \n",
            "\n",
            "---------------------------------------------\n",
            "Dado que la capacidad instalada no es suficiente para generar la energ√≠a que consume¬† el pa√≠s, existe un alto grado de incertidumbre en esta actividad primordial de adquisici√≥n, que debe ser controlada √≥ptimamente y en la cual se hace necesario sostener un equilibrio en la cantidad de energ√≠a por comprar en cada una de las modalidades, la ventana de tiempo anticipado para realizar la compra y factores como el flujo de caja, la demanda de los suscriptores y la fluctuaci√≥n de precios por la volatilidad del mercado que depende de diversas condiciones econ√≥micas, legales y de medio ambiente, principalmente relacionadas con el clima dado que en Colombia el 68%¬†de la capacidad instalada proviene de fuentes renovables (ACOLGEN, 2020).\n",
            "\n",
            "Estas necesidades se suplen actualmente con modelos que se utilizan desde hace varios a√±os pero que deben ser actualizados utilizando enfoques y tecnolog√≠a de vanguardia, para que permitan ajustar de forma m√°s precisa las variables y proyecciones de la demanda, considerando incluso el ingreso de autogeneradores menores de energ√≠a a trav√©s de paneles solares que modificar√°n la demanda en un futuro cercano si llegan a tener un crecimiento no calculado. \n",
            "\n",
            "---------------------------------------------\n",
            "Dado que la capacidad instalada no es suficiente para generar la energ√≠a que consume¬† el pa√≠s, existe un alto grado de incertidumbre en esta actividad primordial de adquisici√≥n, que debe ser controlada √≥ptimamente y en la cual se hace necesario sostener un equilibrio en la cantidad de energ√≠a por comprar en cada una de las modalidades, la ventana de tiempo anticipado para realizar la compra y factores como el flujo de caja, la demanda de los suscriptores y la fluctuaci√≥n de precios por la volatilidad del mercado que depende de diversas condiciones econ√≥micas, legales y de medio ambiente, principalmente relacionadas con el clima dado que en Colombia el 68%¬†de la capacidad instalada proviene de fuentes renovables (ACOLGEN, 2020).\n",
            "\n",
            "Estas necesidades se suplen actualmente con modelos que se utilizan desde hace varios a√±os pero que deben ser actualizados utilizando enfoques y tecnolog√≠a de vanguardia, para que permitan ajustar de forma m√°s precisa las variables y proyecciones de la demanda, considerando incluso el ingreso de autogeneradores menores de energ√≠a a trav√©s de paneles solares que modificar√°n la demanda en un futuro cercano si llegan a tener un crecimiento no calculado. \n",
            "\n",
            "---------------------------------------------\n",
            "Dado que la capacidad instalada no es suficiente para generar la energ√≠a que consume¬† el pa√≠s, existe un alto grado de incertidumbre en esta actividad primordial de adquisici√≥n, que debe ser controlada √≥ptimamente y en la cual se hace necesario sostener un equilibrio en la cantidad de energ√≠a por comprar en cada una de las modalidades, la ventana de tiempo anticipado para realizar la compra y factores como el flujo de caja, la demanda de los suscriptores y la fluctuaci√≥n de precios por la volatilidad del mercado que depende de diversas condiciones econ√≥micas, legales y de medio ambiente, principalmente relacionadas con el clima dado que en Colombia el 68%¬†de la capacidad instalada proviene de fuentes renovables (ACOLGEN, 2020).\n",
            "\n",
            "Estas necesidades se suplen actualmente con modelos que se utilizan desde hace varios a√±os pero que deben ser actualizados utilizando enfoques y tecnolog√≠a de vanguardia, para que permitan ajustar de forma m√°s precisa las variables y proyecciones de la demanda, considerando incluso el ingreso de autogeneradores menores de energ√≠a a trav√©s de paneles solares que modificar√°n la demanda en un futuro cercano si llegan a tener un crecimiento no calculado. \n",
            "\n",
            "---------------------------------------------\n",
            "Para los comercializadores en Colombia es m√°s dif√≠cil predecir la demanda de largo plazo para saber cu√°nta energ√≠a comprar porque los modelos actualmente utilizados como ARIMA, que son realizados para horizontes de corto plazo, con los cuales algunos comercializadores como EMCALI EICE ESP no hacen predicci√≥n de mediano y largo plazo (ver tabla 1), porque no les ofrecen la precisi√≥n requerida o no incorporan los suficientes aspectos determinantes del consumo como la variabilidad de factores clim√°ticos, as√≠ como econ√≥micos que afectan la capacidad de pago de los usuarios o indicadores de productividad general como el PIB. \n",
            "\n",
            "---------------------------------------------\n",
            "En ocasiones se incrementan las p√©rdidas no t√©cnicas o se desborda la demanda por auge en el sector de la construcci√≥n de vivienda lo cual tambi√©n afecta la demanda. \n",
            "\n",
            "---------------------------------------------\n",
            "En ocasiones se incrementan las p√©rdidas no t√©cnicas o se desborda la demanda por auge en el sector de la construcci√≥n de vivienda lo cual tambi√©n afecta la demanda. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Tabla 1 Proyecciones de demanda en el mercado regulado en kWh/mes realizadas en EMCALI EICE ESP para compra de energ√≠a, en los a√±os 2017 a 2020 usando modelos de media m√≥vil, realizados con tres meses de anticipaci√≥n para 12 meses posteriores.\n",
            "\n",
            "\n",
            "Este problema¬†genera diversos inconvenientes a estos actores del mercado, que a la postre se trasladan a los usuarios, tales como¬†desabastecimiento energ√©tico a la industria, aumento en el precio final de la energ√≠a, generaci√≥n de multas y p√©rdidas econ√≥micas para los comercializadores, produce crisis financiera en las regiones, reducci√≥n de la productividad general e incremento del descontento en los usuarios. \n",
            "\n",
            "---------------------------------------------\n",
            "Teniendo en cuenta el impacto de las proyecciones del consumo en el proceso de adquisici√≥n y comercializaci√≥n de la energ√≠a el√©ctrica y la necesidad de adquirirla de forma anticipada para abastecer a las regiones, en este proyecto se busca resolver la pregunta: ¬øC√≥mo mejorar la predicci√≥n de largo plazo en la demanda de energ√≠a el√©ctrica en Cali, utilizando t√©cnicas y modelos de inteligencia artificial?\n",
            "\n",
            "\n",
            "5. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "5.2.1 Dise√±ar diferentes modelos de aprendizaje autom√°tico para realizar la predicci√≥n de la demanda de energ√≠a el√©ctrica de largo plazo. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "5.2.2 Seleccionar el mejor modelo de aprendizaje autom√°tico para realizar la predicci√≥n de la demanda de energ√≠a el√©ctrica de largo plazo a partir de los modelos de Machine Learning dise√±ados. \n",
            "\n",
            "---------------------------------------------\n",
            "Aunque es cierto que las condiciones de cada pa√≠s son diferentes, con el conocimiento alcanzado se han logrado identificar muchas de las variables que determinan la demanda de la energ√≠a el√©ctrica. \n",
            "\n",
            "---------------------------------------------\n",
            "\t\n",
            "\n",
            "6.1.2 Pron√≥sticos de la demanda de energ√≠a el√©ctrica. \n",
            "\n",
            "---------------------------------------------\n",
            "El proceso de pronosticar la demanda de electricidad por parte de los actores del mercado regulado de energ√≠a se basa en los horizontes de tiempo de pron√≥stico y en los determinantes del consumo o demanda de electricidad. \n",
            "\n",
            "---------------------------------------------\n",
            "El proceso de pronosticar la demanda de electricidad por parte de los actores del mercado regulado de energ√≠a se basa en los horizontes de tiempo de pron√≥stico y en los determinantes del consumo o demanda de electricidad. \n",
            "\n",
            "---------------------------------------------\n",
            "Rueda et al. (Rueda et al., 2011) describen porqu√© es importante el pron√≥stico de la demanda de electricidad por horizontes seg√∫n el tipo de actor en el mercado. \n",
            "\n",
            "---------------------------------------------\n",
            "Para los comercializadores en el mediano y largo plazo, quienes son el objetivo de este proyecto, el pron√≥stico de demanda es un insumo fundamental para el an√°lisis del comportamiento del mercado y la definici√≥n de los planes estrat√©gicos y operativos para la comercializaci√≥n y adquisici√≥n de la electricidad. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "Se han desarrollado numerosos m√©todos para la previsi√≥n de la demanda de electricidad, en su mayor√≠a de corto plazo lo cual representa la debilidad para encontrar modelos que proporcionen el pron√≥stico de largo plazo. \n",
            "\n",
            "---------------------------------------------\n",
            "6.2 Dominio de la Soluci√≥n\n",
            "\n",
            "La soluci√≥n al problema del pron√≥stico de la demanda de electricidad de largo plazo se encuentra en el √°mbito de la inteligencia artificial (ver figura 1) y el aspecto de los determinantes del consumo de energ√≠a en el √°mbito de la econometr√≠a. \n",
            "\n",
            "---------------------------------------------\n",
            "Alguna selecci√≥n de ellos ser√° la base para pronosticar la demanda de electricidad en Colombia en este proyecto. \n",
            "\n",
            "---------------------------------------------\n",
            "A continuaci√≥n, se presentan estudios realizados en diferentes pa√≠ses y¬†diferentes a√±os¬†principalmente en temas de an√°lisis de series de tiempo y t√©cnicas de Machine Learning,¬†puesto que estos temas resultan fundamentales para el planteamiento del modelo¬†que¬†permita predecir la demanda de energ√≠a el√©ctrica en un horizonte de mediano-largo plazo. \n",
            "\n",
            "---------------------------------------------\n",
            "Las palabras claves utilizadas en las b√∫squedas realizadas incluyeron: inteligencia artificial, aprendizaje autom√°tico, modelos econom√©tricos, predicci√≥n en series temporales, pron√≥stico de demanda de electricidad. \n",
            "\n",
            "---------------------------------------------\n",
            "7.1 Trabajos seleccionados\n",
            "\n",
            "Se encontr√≥ mucha literatura relacionada con el pron√≥stico de demanda de electricidad  de corto plazo, a diferencia de la encontrada para largo plazo, sin embargo los enfoques en este aspecto son muy novedosos y variados. \n",
            "\n",
            "---------------------------------------------\n",
            "Esta propuesta fue aplicada en la India, con el fin de llenar un vac√≠o en el pron√≥stico de la demanda de energ√≠a el√©ctrica de largo plazo. \n",
            "\n",
            "---------------------------------------------\n",
            "Este estudio se aplic√≥ en Hong Kong con el fin de cuantificar el impacto de cambios socioecon√≥micos y clim√°ticos en la demanda de energ√≠a el√©ctrica mensual a largo plazo. \n",
            "\n",
            "---------------------------------------------\n",
            "Se adopt√≥ el modelo GBDT que result√≥ ser el mas adecuado para el pron√≥stico de la demanda de energ√≠a el√©ctrica de largo plazo en Hong Kong. \n",
            "\n",
            "---------------------------------------------\n",
            "Este estudio fue aplicado en Bogot√°, con el fin de identificar las variables que tienen mayor impacto en la predicci√≥n de la demanda de energ√≠a. \n",
            "\n",
            "---------------------------------------------\n",
            "Se encontr√≥ como resultado que las variables que mas impacto tienen en la predicci√≥n de la demanda de energ√≠a para el primer proceso son los usuarios finales, la temperatura de superficie y el precio de la energ√≠a el√©ctrica y para el segundo (econom√©trico) fue la elasticidad de precios, el PIB y los usuarios. \n",
            "\n",
            "---------------------------------------------\n",
            "Este estudio se aplic√≥ en Suecia, con el fin de involucrar los determinantes de la demanda y la oferta para investigar las relaciones causales a corto y largo plazo entre el sistema de energ√≠a el√©ctrica, el desempe√±o macroecon√≥mico, la demograf√≠a, la calidad ambiental y la formaci√≥n de capital. \n",
            "\n",
            "---------------------------------------------\n",
            "Se us√≥ un modelo de memoria de corto plazo (LSTM) con redes neuronales recurrentes (RNN), con datos de 1990 a 2018 y proyecciones de demanda hasta 2050. \n",
            "\n",
            "---------------------------------------------\n",
            "Este estudio fue realizado para la predicci√≥n de la demanda de energ√≠a para el Sistema  Operador Independiente de California, que surte los estados de California y Nevada para 2.5 a√±os entre 2018 y 2021. \n",
            "\n",
            "---------------------------------------------\n",
            "El modelo LSTM + EMD H√≠brido super√≥ con mejores resultados al XGBoost y LR en predicciones de demanda de electricidad de corto y largo plazo. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "Contexto: relacionados con el consumo o demanda de electricidad y su pron√≥stico a largo plazo. \n",
            "\n",
            "---------------------------------------------\n",
            "Determinar objetivos del Negocio:\n",
            "\n",
            "Teniendo en cuenta el alcance se define el objetivo general del negocio, al cual el proyecto de anal√≠tica de impactar con respecto a la demanda de energ√≠a el√©ctrica.\n",
            "\n",
            "Evaluar la situaci√≥n:\n",
            "\n",
            "Implica una b√∫squeda de datos m√°s detallada, incluyendo variables end√≥genas y ex√≥genas, as√≠ como otros factores que deben considerarse al determinar el objetivo  del  an√°lisis  de  datos  y  el  plan  del proyecto.\n",
            "\n",
            "Realizar el plan del proyecto:\n",
            "\n",
            "Se define un listado ordenado y priorizado de los requisitos necesarios para desarrollo del modelo y su posterior validaci√≥n, bas√°ndose en los objetivos espec√≠ficos del proyecto.\n",
            "\n",
            "\n",
            "8.2 Fase 2: Comprensi√≥n de los datos.¬†\n",
            "\n",
            "Esta fase busca la familiarizaci√≥n con los datos que van a ser objeto de an√°lisis. \n",
            "\n",
            "---------------------------------------------\n",
            "Avances recientes en la predicci√≥n de la demanda de electricidad usando modelos no lineales. \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë An√°lisis del Texto Seleccionado ‚Äì Enrique Manzano"
      ],
      "metadata": {
        "id": "-QFIfdL-hS6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file from GitHub\n",
        "url = \"https://raw.githubusercontent.com/semurillas/NLP_MIAA_252/main/Texts/EL_PRINCIPITO.txt\"\n",
        "text_file_path = \"EL_PRINCIPITO.txt\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(text_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Archivo descargado como: {text_file_path}\")\n",
        "\n",
        "# Step 2: Read the TXT file\n",
        "def read_txt(file_path):\n",
        "    \"\"\"Reads a .txt file and returns its text content.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    return text\n",
        "\n",
        "text_content = read_txt(text_file_path)\n",
        "\n",
        "# Step 3: Process with NLP model\n",
        "doc = nlp(text_content)\n",
        "print(text_file_path,' has been processed with NLP model succesfully')"
      ],
      "metadata": {
        "id": "9vD4Tp0ih8_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4340a733-48ff-4718-de81-bbb3457aa4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado como: EL_PRINCIPITO.txt\n",
            "EL_PRINCIPITO.txt  has been processed with NLP model succesfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOiBMpzhh8_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefa5b13-edff-48b9-baaa-b4370d0159ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EL PRINCIPITO \n",
              "\n",
              "ANTOINE DE SAINT-EXUP√âRY \n",
              "\n",
              "\n",
              "\n",
              "A LEON WERTH \n",
              "\n",
              "\n",
              "\n",
              "Pido perd√≥n a los ni√±os por haber dedicado este libro a una persona mayor. Tengo \n",
              "una se√±a excusa: esta persona mayor es el mejor amigo que tengo en el mundo. \n",
              "Pero tengo otra excusa: esta persona mayor es capaz de comprenderlo todo, \n",
              "incluso los libros para ni√±os. Tengo una tercera excusa todav√≠a: esta persona \n",
              "mayor vive en Francia, donde pasa hambre y fr√≠o. Tiene, por consiguiente, una \n",
              "gran necesidad de ser consolada."
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "doc[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mC1RThsh8_1"
      },
      "source": [
        "El documento fue cargado exitosamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThGH-9kzh8_1"
      },
      "source": [
        "**2. Cuantos tokens hay en el archivo?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjkeR1xzh8_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb27aa9a-ff0b-4eac-a7d4-033a05780cee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16948"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvnVMfB-h8_2"
      },
      "source": [
        "**3. Cuantas oraciones hay en el archivo?**\n",
        "<br>Pista: Necesitar√°s una lista primero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tSxi572h8_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff5340f-d716-4ff5-be43-3da70ebd8290"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1422"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "sentences = list(doc.sents)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4irGr4th8_2"
      },
      "source": [
        "**4. Imprime la segunda oraci√≥n del documento**\n",
        "<br> Pista: Los √≠ndices comienzan en 0 y el t√≠tulo cuenta como la primera oraci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21I1bT5bh8_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7479dfb4-8943-40af-caed-d5c8b9cd65b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tengo \n",
              "una se√±a excusa: esta persona mayor es el mejor amigo que tengo en el mundo. \n",
              "Pero tengo otra excusa: esta persona mayor es capaz de comprenderlo todo, \n",
              "incluso los libros para ni√±os."
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkNHXf3Xh8_3"
      },
      "source": [
        "**5. Por cada token en la oraci√≥n anterior, imprime su `text`, `POS` tag, `dep` tag y `lemma`**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvIL2goih8_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcfd4cf-a33d-4c52-8321-d816494295f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text                POS                 dep                 lemma               \n",
            "Tengo               VERB                punct               tener               \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "una                 DET                 det                 uno                 \n",
            "se√±a                NOUN                amod                se√±a                \n",
            "excusa              NOUN                obj                 excusa              \n",
            ":                   PUNCT               punct               :                   \n",
            "esta                DET                 det                 este                \n",
            "persona             NOUN                nsubj               persona             \n",
            "mayor               ADJ                 amod                mayor               \n",
            "es                  AUX                 cop                 ser                 \n",
            "el                  DET                 det                 el                  \n",
            "mejor               ADJ                 amod                mejor               \n",
            "amigo               NOUN                acl                 amigo               \n",
            "que                 PRON                obj                 que                 \n",
            "tengo               VERB                acl                 tener               \n",
            "en                  ADP                 case                en                  \n",
            "el                  DET                 det                 el                  \n",
            "mundo               NOUN                obl                 mundo               \n",
            ".                   PUNCT               dep                 .                   \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "Pero                CCONJ               advmod              Pero                \n",
            "tengo               VERB                ROOT                tener               \n",
            "otra                DET                 det                 otro                \n",
            "excusa              NOUN                obj                 excusa              \n",
            ":                   PUNCT               punct               :                   \n",
            "esta                DET                 det                 este                \n",
            "persona             NOUN                nsubj               persona             \n",
            "mayor               ADJ                 amod                mayor               \n",
            "es                  AUX                 cop                 ser                 \n",
            "capaz               ADJ                 acl                 capaz               \n",
            "de                  ADP                 mark                de                  \n",
            "comprenderlo        VERB                acl                 comprender √©l       \n",
            "todo                PRON                obj                 todo                \n",
            ",                   PUNCT               punct               ,                   \n",
            "\n",
            "                   SPACE               dep                 \n",
            "                   \n",
            "incluso             ADV                 advmod              incluso             \n",
            "los                 DET                 det                 el                  \n",
            "libros              NOUN                appos               libro               \n",
            "para                ADP                 case                para                \n",
            "ni√±os               NOUN                nmod                ni√±o                \n",
            ".                   PUNCT               punct               .                   \n"
          ]
        }
      ],
      "source": [
        "print(\"{:20}{:20}{:20}{:20}\".format(\"Text\", \"POS\", \"dep\", \"lemma\"))\n",
        "for token in sentences[1]:\n",
        "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_:{20}}{token.lemma_:{20}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wZsr_vFh8_3"
      },
      "source": [
        "**6. Implementa un matcher llamado *Swimming* que encuentre las ocurrencias de la frase *Inteligencia Artificial* Write a matcher called 'Swimming' that finds**\n",
        "<br>\n",
        "Pista: Deber√≠as incluir un patr√≥n`'IS_SPACE': True` entre las dos palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXd85y4-h8_3"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'TEXT': 'rosa'}]\n",
        "matcher.add(\"Swimming\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhXA9q1eh8_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b185ae54-3ddb-418b-aeb8-88539d872579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontraron: 11 ocurrencias del  [{'TEXT': 'rosa'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12881893835109366681, 2324, 2325),\n",
              " (12881893835109366681, 11408, 11409),\n",
              " (12881893835109366681, 12584, 12585),\n",
              " (12881893835109366681, 12672, 12673),\n",
              " (12881893835109366681, 12750, 12751),\n",
              " (12881893835109366681, 12827, 12828),\n",
              " (12881893835109366681, 12890, 12891),\n",
              " (12881893835109366681, 12898, 12899),\n",
              " (12881893835109366681, 13966, 13967),\n",
              " (12881893835109366681, 14420, 14421),\n",
              " (12881893835109366681, 16754, 16755)]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "found_matches = matcher(doc)\n",
        "print(\"Se encontraron: {}\".format(len(found_matches)), \"ocurrencias del \", pattern )\n",
        "found_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VXsJUYsh8_4"
      },
      "source": [
        "**7. Imprime el texto al rededor de cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViH6_VnHh8_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7fc838-d36d-4b0a-d8e3-aa85d715d520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ": \" He visto una casa preciosa de ladrillo **rosa** , con geranios \n",
            " en las ventanas y palomas\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "y resulta que no \n",
            " tengo m√°s que una **rosa** ordinaria . Eso y mis tres volcanes que apenas\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "nada , ni en nada se parecen a mi **rosa** . Nadie las ha domesticado ni \n",
            " ustedes han\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            " que las vea podr√° creer indudablemente que m√≠ **rosa** es igual que cualquiera de \n",
            " ustedes . Pero\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "y algunas veces hasta callarse . Porque es mi **rosa** , en fin . \n",
            "\n",
            " Y volvi√≥ con el\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            ". \n",
            " -Lo que hace m√°s importante a tu **rosa** , es el tiempo que t√∫ has perdido con\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "has domesticado . T√∫ eres responsable \n",
            " de tu **rosa** ... \n",
            "\n",
            " -Yo soy responsable de mi rosa ...\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "tu rosa ... \n",
            "\n",
            " -Yo soy responsable de mi **rosa** ... -repiti√≥ el principito a fin de recordarlo \n",
            "\n",
            "\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "una flor , es la imagen de la \n",
            " **rosa** que resplandece en √©l como la llama de una\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "lo que buscan podr√≠an \n",
            " encontrarlo en una sola **rosa** o en un poco de agua ... \n",
            "\n",
            " -Sin\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "se ha comido o no se ha comido una **rosa** ... \n",
            "\n",
            " Pero miren al cielo y preg√∫ntense :\n",
            "-------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _, start, end in found_matches:\n",
        "    span = doc[start:end]\n",
        "    surrounding_span = doc[start-9:end+9]\n",
        "    highlighted_text = []\n",
        "    for token in surrounding_span:\n",
        "        if token.i >= start and token.i < end:\n",
        "            highlighted_text.append(f'**{token.text}**')\n",
        "        else:\n",
        "            highlighted_text.append(token.text)\n",
        "    print(' '.join(highlighted_text))\n",
        "    print('-------------------------------------------')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27jRbexwh8_4"
      },
      "source": [
        "**8. Imprime la oraci√≥n que contiene cada match encontrado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVyg3g56h8_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcf1da7-b929-4b11-c2be-da71d810329d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Si les decimos a \n",
            "las personas mayores: \"He visto una casa preciosa de ladrillo rosa, con geranios \n",
            "en las ventanas y palomas en el tejado\", jam√°s llegar√°n a imaginarse c√≥mo es esa \n",
            "\n",
            "\n",
            "\n",
            "9 \n",
            "\n",
            "\n",
            "\n",
            "Tierra no hay posibilidad de deshollinar los volcanes; los hombres somos \n",
            "demasiado peque√±os. \n",
            "\n",
            "---------------------------------------------\n",
            "44 \n",
            "\n",
            "\n",
            "\n",
            "Y luego continu√≥ dici√©ndose: \"Me cre√≠a rico con una flor √∫nica y resulta que no \n",
            "tengo m√°s que una rosa ordinaria. \n",
            "\n",
            "---------------------------------------------\n",
            "El principito se fue a ver las rosas a las que dijo: \n",
            "\n",
            "-No son nada, ni en nada se parecen a mi rosa. \n",
            "\n",
            "---------------------------------------------\n",
            "Cualquiera \n",
            "que las vea podr√° creer indudablemente que m√≠ rosa es igual que cualquiera de \n",
            "ustedes. \n",
            "\n",
            "---------------------------------------------\n",
            "Porque es mi rosa, en fin. \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "-Lo que hace m√°s importante a tu rosa, es el tiempo que t√∫ has perdido con ella. \n",
            "\n",
            "---------------------------------------------\n",
            "T√∫ eres responsable \n",
            "de tu rosa... \n",
            "\n",
            "---------------------------------------------\n",
            "\n",
            "\n",
            "-Yo soy responsable de mi rosa... -repiti√≥ el principito a fin de recordarlo \n",
            "\n",
            "XXII \n",
            "\n",
            "\n",
            "\n",
            "-¬°Buenos d√≠as! -dijo el principito. \n",
            "\n",
            "-¬°Buenos d√≠as! -respondi√≥ el guardav√≠as. \n",
            "\n",
            "-¬øQu√© haces aqu√≠? -le pregunt√≥ el principito. \n",
            "\n",
            "---------------------------------------------\n",
            "Como sus labios entreabiertos esbozaron una sonrisa, me dije: \"Lo que m√°s me \n",
            "emociona de este principito dormido es su fidelidad a una flor, es la imagen de la \n",
            "rosa que resplandece en √©l como la llama de una l√°mpara, incluso cuando \n",
            "duerme... \" \n",
            "\n",
            "---------------------------------------------\n",
            "-Y sin embargo, lo que buscan podr√≠an \n",
            "encontrarlo en una sola rosa o en un poco de agua... \n",
            "\n",
            "---------------------------------------------\n",
            "Para ustedes que quieren al principito, lo mismo que \n",
            "para m√≠, nada en el universo habr√° cambiado si en cualquier parte, quien sabe \n",
            "d√≥nde, un cordero desconocido se ha comido o no se ha comido una rosa... \n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    for _, start, end in found_matches:\n",
        "        if sentence.start <= start and sentence.end >= end:\n",
        "            print(sentence.text, '\\n')\n",
        "            print(\"---------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}